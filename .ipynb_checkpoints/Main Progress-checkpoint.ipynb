{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5215a60",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch as torch\n",
    "import pywt\n",
    "from scipy.signal import welch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.optim as optim\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import shap\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import chi2_contingency, ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5829843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, Subset, random_split\n",
    "\n",
    "import pywt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac127f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGUtil:\n",
    "    @staticmethod\n",
    "    def load_data(file_path, column_names=['spike hz']):\n",
    "        \"\"\"Load multi-channel EEG data from a CSV file and normalize it.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path: Path to the CSV file.\n",
    "        - column_names: List of EEG signal column names to load.\n",
    "\n",
    "        Returns:\n",
    "        - signal: 2D numpy array (channels √ó time), normalized.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        # Á°Æ‰øùÊâÄÊúâÂàóÈÉΩÂ≠òÂú®\n",
    "        available_columns = [col for col in column_names if col in data.columns]\n",
    "        if not available_columns:\n",
    "            raise ValueError(f\"None of the specified columns {column_names} exist in {file_path}\")\n",
    "\n",
    "        signal = data[available_columns].values.T  # (channels, time)\n",
    "\n",
    "        # **üî• Âº∫Âà∂ z-score ÂΩí‰∏ÄÂåñ**\n",
    "        mean = np.mean(signal, axis=1, keepdims=True)\n",
    "        std = np.std(signal, axis=1, keepdims=True)\n",
    "\n",
    "        # Èò≤Ê≠¢Ê†áÂáÜÂ∑Æ‰∏∫ 0ÔºåÈÅøÂÖç NaN\n",
    "        std[std == 0] = 1e-8  \n",
    "        \n",
    "        #signal = (signal - mean) / std  # ÂΩí‰∏ÄÂåñ\n",
    "        \n",
    "        return signal\n",
    "\n",
    "    @staticmethod\n",
    "    def padding(signal, target_length, mode=\"constant\", constant_value=0):\n",
    "        \"\"\"Pad or truncate multi-channel signal to the target length.\"\"\"\n",
    "        signal = np.array(signal)  # Ensure it's a NumPy array\n",
    "        channels, current_length = signal.shape\n",
    "        \n",
    "        if current_length >= target_length:\n",
    "            return signal[:, :target_length]  # Truncate\n",
    "\n",
    "        padding_size = target_length - current_length\n",
    "        if mode == \"constant\":\n",
    "            pad_values = np.full((channels, padding_size), constant_value)\n",
    "        elif mode == \"reflect\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='reflect')[:, -padding_size:]\n",
    "        elif mode == \"cyclic\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='wrap')[:, -padding_size:]\n",
    "        elif mode == \"edge\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='edge')[:, -padding_size:]\n",
    "        elif mode == \"random\":\n",
    "            pad_values = np.random.uniform(low=np.min(signal), high=np.max(signal), size=(channels, padding_size))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported padding mode: {mode}\")\n",
    "\n",
    "        return np.hstack((signal, pad_values))  # Concatenate along time axis\n",
    "    \n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_folder, outcome_file=None, ssd_file=None,start_time=16,target_length=600, strategy='padding', \n",
    "                 padding_mode=\"constant\", use_labels=False, augment=False,num_good=1,num_bad=1,column_names=['spike hz']):\n",
    "        \n",
    "        \"\"\"\n",
    "        EEG signal datasets with support for data enhancement (random fill). \n",
    "\n",
    "        Parameters: \n",
    "        - data_folder: path of the EEG data folder \n",
    "        - outcome_file: CSV file with patient ID and outcome (optional) \n",
    "        - target_length: indicates the padding length of the target \n",
    "        - strategy: wavelet ('padding', 'wavelet', 'psd') \n",
    "        - padding_mode: indicates the fill mode ('constant', 'reflect',...). \n",
    "        - use_labels: indicates whether to use labels \n",
    "        - augment: Whether data enhancement is enabled (randomly fill different lengths) \n",
    "        \"\"\"\n",
    "\n",
    "        self.use_labels = use_labels\n",
    "        self.data_folder = data_folder\n",
    "        self.target_length = target_length\n",
    "        self.strategy = strategy\n",
    "        self.padding_mode = padding_mode\n",
    "        self.augment = augment # ÊòØÂê¶ÂêØÁî®Êï∞ÊçÆÂ¢ûÂº∫\n",
    "        self.column_names = column_names #Feature Chosen\n",
    "        \n",
    "        self.num_good = num_good\n",
    "        self.num_bad = num_bad\n",
    "        \n",
    "        self.start_time=start_time\n",
    "        self.end_time=int((target_length/12)+self.start_time)\n",
    "\n",
    "        self.file_list = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "       \n",
    "        # Read 'rosc sec' start time\n",
    "        ssd_df = pd.read_csv(ssd_file)\n",
    "        # Get `pat_ID`\n",
    "        ssd_df[\"pat_ID\"] = ssd_df[\"fn\"].str.extract(r\"(ICARE_\\d+)\")\n",
    "        #  Take the smallest 'rosc sec' of each 'pat ID' \n",
    "        self.rosc_dict = ssd_df.groupby(\"pat_ID\")[\"rosc_sec\"].min().to_dict()\n",
    "        \n",
    "        # LOAD Labels\n",
    "        self.outcome_dict = {}\n",
    "        if use_labels and outcome_file:\n",
    "            self.outcome_data = pd.read_csv(outcome_file)\n",
    "            self.outcome_dict = self.outcome_data.set_index('pat_ID')['outcome'].to_dict()\n",
    "            self.file_list = [f for f in self.file_list if f.split('.')[0] in self.outcome_dict]\n",
    "        \n",
    "        self.valid_files = []\n",
    "        # Filter EEG data conforming to 16h-68h rules\n",
    "        for f in self.file_list:\n",
    "            pat_id = f.split('.')[0]\n",
    "\n",
    "            if pat_id in self.rosc_dict:\n",
    "                file_path = os.path.join(self.data_folder, f)\n",
    "                signal = EEGUtil.load_data(file_path, column_names=self.column_names)  #Load Multiple Channel\n",
    "                rosc_sec = float(self.rosc_dict[pat_id])  # Ensure `rosc_sec` is a float\n",
    "\n",
    "                # **EEG recording time range**\n",
    "                start_time = rosc_sec\n",
    "                end_time = start_time + signal.shape[1] * 300  # Each point represents 5 minutes (=300 seconds)\n",
    "                # **Skip if the data is completely outside the 16h-68h observation window**\n",
    "                if end_time < self.start_time * 3600 or start_time > self.end_time * 3600:\n",
    "                    #print(f\"‚ùå Skipping {pat_id}: EEG data is out of 16h-68h range ({start_time/3600:.1f}h - {end_time/3600:.1f}h)\")\n",
    "                    continue  \n",
    "\n",
    "                # **Align to the 16h-68h window**\n",
    "                aligned_signal = self.align_signal(signal, rosc_sec)\n",
    "                self.valid_files.append((f, aligned_signal))\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(self.valid_files)} valid EEG files (filtered from {len(self.file_list)} total)\")\n",
    "\n",
    "        # **Count Good/Bad Outcome samples**\n",
    "        self.good_outcome_count = sum(1 for f, _ in self.valid_files if self.get_label(f.split('.')[0]) == 1)\n",
    "        self.bad_outcome_count = len(self.valid_files) - self.good_outcome_count\n",
    "\n",
    "        print(f\"Good Outcome: {self.good_outcome_count}, Bad Outcome: {self.bad_outcome_count}\")\n",
    "\n",
    "        # **Data Augmentation: Expanding indices**\n",
    "        self.expanded_indices = []\n",
    "        for idx, (filename, signal) in enumerate(self.valid_files):\n",
    "            patient_id = filename.split('.')[0]\n",
    "            label = self.get_label(patient_id) if self.use_labels else -1\n",
    "\n",
    "            if self.augment:\n",
    "                if self.use_labels:\n",
    "                    # Good Outcome √ó10, Bad Outcome √ó2\n",
    "                    if label == 1:\n",
    "                        repeat_times = self.num_good\n",
    "                    else:\n",
    "                        repeat_times = self.num_bad\n",
    "                else:\n",
    "                    repeat_times = 1  # Data augmentation for unlabeled data\n",
    "            else:\n",
    "                repeat_times = 1  \n",
    "\n",
    "            for _ in range(repeat_times):\n",
    "                self.expanded_indices.append((idx, label))  # ‚úÖ Store index & label\n",
    "    \n",
    "    def __len__(self):\n",
    "        # print(f\"üìè Dataset __len__: {len(self.expanded_indices)}\")  # Ensure `expanded_indices` length is correct\n",
    "        return len(self.expanded_indices)  # ‚úÖ Must return the number of samples after data augmentation\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original_idx, label = self.expanded_indices[idx]\n",
    "        filename, signal = self.valid_files[original_idx]  # Directly retrieve the **aligned** signal\n",
    "        patient_id = filename.split('.')[0]\n",
    "\n",
    "        # Get label\n",
    "        label = -1\n",
    "        if self.use_labels:\n",
    "            label = self.get_label(patient_id)\n",
    "\n",
    "        # Perform data augmentation (varies each time)\n",
    "        if self.augment:\n",
    "            augmented_signal = self.augment_signal(signal)  # ‚úÖ Apply augmentation directly to the **aligned signal**\n",
    "        else:\n",
    "            augmented_signal = signal  # ‚úÖ Use the aligned signal directly\n",
    "\n",
    "        return torch.tensor(augmented_signal, dtype=torch.float32), label\n",
    "    \n",
    "    def align_signal(self, signal, rosc_sec):\n",
    "        \"\"\" Align EEG data to the 16h-68h observation period \"\"\"\n",
    "\n",
    "        target_length = self.target_length  # Number of `5min` windows for 52 hours (624)\n",
    "        total_signal_length = signal.shape[1]  # Total length of the EEG recording\n",
    "        \n",
    "        rosc_sec = float(rosc_sec)  # ‚úÖ Ensure `rosc_sec` is a float\n",
    "        # print(f\"üîç Processing patient data: rosc_sec={rosc_sec}, total_signal_length={total_signal_length}\")\n",
    "\n",
    "        # **Calculate the starting position of '16h' in the EEG recording**\n",
    "        start_sec = (self.start_time * 3600) - rosc_sec  \n",
    "        if start_sec < 0:\n",
    "            pad_size = abs(start_sec) / 300  # Calculate the number of windows to pad\n",
    "            start_index = 0  # Start extracting data from the beginning of the EEG recording\n",
    "        else:\n",
    "            pad_size = 0  # No padding needed\n",
    "            start_index = int(start_sec // 300)  # ‚úÖ Convert to integer\n",
    "\n",
    "        # **Calculate the endpoint index for '68h'**\n",
    "        end_index = int(min(start_index + target_length, total_signal_length))  # ‚úÖ Convert to integer\n",
    "\n",
    "        # **Extract EEG data for the 16h-68h observation period**\n",
    "        aligned_signal = signal[:, start_index:end_index]\n",
    "\n",
    "        # **Pre-padding (if `rosc_sec > 16h`)**\n",
    "        if pad_size > 0:\n",
    "            aligned_signal = EEGDataset.pad_signal(aligned_signal, target_length, self.padding_mode, padding_position=\"pre\")\n",
    "\n",
    "        # **Post-padding (if data is less than 52 hours)**\n",
    "        aligned_signal = EEGDataset.pad_signal(aligned_signal, target_length, self.padding_mode, padding_position=\"post\")\n",
    "\n",
    "        # print(f\"‚úÖ Aligned signal length: {len(aligned_signal)}\")\n",
    "        return aligned_signal\n",
    "    \n",
    "    def pad_signal(signal, target_length, mode=\"constant\", constant_value=np.nan, padding_position=\"post\"):\n",
    "        \"\"\" Pad EEG signal to ensure it reaches `target_length`.\n",
    "\n",
    "        Parameters:\n",
    "        - signal: Original EEG signal (numpy array)\n",
    "        - target_length: Target length (52h = 624 `5min` windows)\n",
    "        - mode: Padding mode:\n",
    "            - `constant`: Fill with a fixed value (`constant_value`)\n",
    "            - `reflect`: Mirror padding\n",
    "            - `cyclic`: Cyclic padding\n",
    "            - `edge`: Edge padding\n",
    "            - `random`: Fill with random values between [min, max]\n",
    "        - padding_position: `\"pre\"` (pad at the beginning) or `\"post\"` (pad at the end)\n",
    "\n",
    "        Returns:\n",
    "        - Padded EEG signal (numpy array)\n",
    "        \"\"\"\n",
    "\n",
    "        channels, current_length = signal.shape\n",
    "        \n",
    "        if current_length >= target_length:\n",
    "            return signal[:, :target_length]  # Truncate if already long enough\n",
    "\n",
    "        padding_size = target_length - current_length  # Number of elements to pad\n",
    "\n",
    "        if mode == \"constant\":\n",
    "            pad_values = np.full((channels, padding_size), constant_value)  # Make sure padding shape matches\n",
    "        elif mode == \"reflect\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='reflect')[:, -padding_size:]\n",
    "        elif mode == \"cyclic\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='wrap')[:, -padding_size:]\n",
    "        elif mode == \"edge\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='edge')[:, -padding_size:]\n",
    "        elif mode == \"random\":\n",
    "            pad_values = np.random.uniform(low=np.min(signal), high=np.max(signal), size=(channels, padding_size))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported padding mode: {mode}\")\n",
    "\n",
    "        # Ensure proper concatenation along the time axis\n",
    "        if padding_position == \"pre\":\n",
    "            padded_signal = np.hstack((pad_values, signal))  # Pad at the beginning\n",
    "        else:\n",
    "            padded_signal = np.hstack((signal, pad_values))  # Pad at the end\n",
    "\n",
    "        return padded_signal[:, :target_length]  # Ensure exact target length\n",
    "    \n",
    "    def augment_signal(self, signal):\n",
    "        \"\"\" Data augmentation: Shift EEG data within the 16h-68h observation period \"\"\"\n",
    "\n",
    "        target_length = self.target_length  # Number of `5min` windows for 52 hours (624)\n",
    "        channels, current_length = signal.shape  # Current EEG recording length\n",
    "\n",
    "        # **Check if already aligned to 16h-68h before augmentation**\n",
    "        if current_length != target_length:\n",
    "            raise ValueError(f\"Before augmentation, signal length should be {target_length}, but received {current_length}\")\n",
    "\n",
    "        # **Augmentation Strategy 1: Random time shift within ¬±60min**\n",
    "        max_shift = 12  # `5min` windows, 60 minutes = 12 data points\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)  # Random shift in [-12, 12]\n",
    "\n",
    "        # **Compute new starting index and ensure it remains within bounds**\n",
    "        start_index = max(0, min(current_length - target_length, shift))\n",
    "        end_index = min(start_index + target_length, current_length)\n",
    "\n",
    "        # **Extract EEG data after shifting**\n",
    "        augmented_signal = signal[:, start_index:end_index]\n",
    "\n",
    "        # **Augmentation Strategy 2: Apply padding based on `shift` direction**\n",
    "        if augmented_signal.shape[1] < target_length:\n",
    "            padding_size = target_length - augmented_signal.shape[1]\n",
    "\n",
    "            if shift > 0:\n",
    "                # **ÂêëÂè≥Âπ≥Áßª: Âú®ÂâçÈù¢Â°´ÂÖÖ**\n",
    "                pad_values = self.pad_signal(np.zeros((channels, padding_size)), target_length, self.padding_mode)\n",
    "                augmented_signal = np.hstack((pad_values, augmented_signal))  # **Á°Æ‰øùÂΩ¢Áä∂Ê≠£Á°Æ**\n",
    "            elif shift < 0:\n",
    "                # **ÂêëÂ∑¶Âπ≥Áßª: Âú®ÂêéÈù¢Â°´ÂÖÖ**\n",
    "                pad_values = self.pad_signal(np.zeros((channels, padding_size)), target_length, self.padding_mode)\n",
    "                augmented_signal = np.hstack((augmented_signal, pad_values))\n",
    "            else:\n",
    "                # **‰∏çÂπ≥ÁßªÔºåÁõ¥Êé•Â°´ÂÖÖ**\n",
    "                augmented_signal = self.pad_signal(augmented_signal, target_length, self.padding_mode)\n",
    "\n",
    "        return augmented_signal\n",
    "\n",
    "    def get_label(self, patient_id):\n",
    "        \"\"\" Get sample label (1 = Good Outcome, 0 = Bad Outcome) \"\"\"\n",
    "        return 1 if self.outcome_dict.get(patient_id, 'Bad Outcome') == 'Good Outcome' else 0\n",
    "\n",
    "    def compare_data_augmentation(self):\n",
    "        \"\"\" Compare the number of samples before and after data augmentation. \"\"\"\n",
    "        original_count = len(self.valid_files)  # Count only files that meet the 16h condition\n",
    "        augmented_count = len(self.expanded_indices)  # Count the number of augmented samples\n",
    "\n",
    "        print(f\"Data count before augmentation: {original_count}\")\n",
    "        print(f\"Data count after augmentation: {augmented_count}\")\n",
    "        print(f\"Augmentation ratio: {augmented_count / original_count:.2f}x\")\n",
    "\n",
    "        if self.use_labels:\n",
    "            # Count Good Outcome and Bad Outcome samples in original data (filtered_files)\n",
    "            good_outcome_original = sum(1 for f, _ in self.valid_files if self.get_label(f.split('.')[0]) == 1)\n",
    "            bad_outcome_original = original_count - good_outcome_original  # Remaining are Bad Outcome samples\n",
    "\n",
    "            # Count Good Outcome and Bad Outcome samples after augmentation\n",
    "            good_outcome_augmented = sum(\n",
    "                1 for (idx, _) in self.expanded_indices  # ‚úÖ Use only idx, ignore label\n",
    "                if self.get_label(self.valid_files[idx][0].split('.')[0]) == 1\n",
    "            )\n",
    "            bad_outcome_augmented = augmented_count - good_outcome_augmented  # Remaining are Bad Outcome samples\n",
    "\n",
    "            print(f\"Good Outcome before augmentation: {good_outcome_original}, after augmentation: {good_outcome_augmented}\")\n",
    "            print(f\"Bad Outcome before augmentation: {bad_outcome_original}, after augmentation: {bad_outcome_augmented}\")\n",
    "\n",
    "        return original_count, augmented_count\n",
    "    \n",
    "    \n",
    "# AugmentedEEGDataset (ÈÄÇÈÖçÂ§öÈÄöÈÅì)\n",
    "class AugmentedEEGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, eeg_dataset_instance, augment=True, num_good=10, num_bad=2):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.eeg_dataset_instance = eeg_dataset_instance  # ‰øùÂ≠òÂÆû‰æã\n",
    "        self.augment = augment\n",
    "        self.num_good = num_good\n",
    "        self.num_bad = num_bad\n",
    "        self.expanded_data = []\n",
    "\n",
    "        for i in range(len(base_dataset)):\n",
    "            signal, label = base_dataset[i]\n",
    "            repeat = num_good if label == 1 else num_bad  # ÊåâÁ±ªÂà´ÂÜ≥ÂÆöÂ¢ûÂº∫ÊØî‰æã\n",
    "\n",
    "            for _ in range(repeat):\n",
    "                # **üî• ÂÖºÂÆπÂ§öÈÄöÈÅìÊï∞ÊçÆ**\n",
    "                signal_np = signal.numpy()\n",
    "                if signal_np.ndim == 2:\n",
    "                    augmented_signal = self.eeg_dataset_instance.augment_signal(signal_np)\n",
    "                else:\n",
    "                    augmented_signal = self.eeg_dataset_instance.augment_signal(signal_np[np.newaxis, :])  # **ÂçïÈÄöÈÅìÂÖºÂÆπ**\n",
    "\n",
    "                self.expanded_data.append((augmented_signal, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.expanded_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        signal, label = self.expanded_data[idx]\n",
    "        return torch.tensor(signal, dtype=torch.float32), label\n",
    "# ÁªüËÆ°Á±ªÂà´‰ø°ÊÅØ\n",
    "def count_labels(dataset):\n",
    "    labels = [dataset[i][1] for i in range(len(dataset))]  # ÂèñÂá∫ÊâÄÊúâÊ†∑Êú¨ÁöÑ label\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    return dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4706cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 244 valid EEG files (filtered from 244 total)\n",
      "Good Outcome: 44, Bad Outcome: 200\n",
      "Train set size (before augmentation): 194\n",
      "Train set label distribution: {0: 158, 1: 36}\n",
      "Test set size: 49\n",
      "Test set label distribution: {0: 41, 1: 8}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameter settings\n",
    "latent_dim = 10  # Dimension of the latent space\n",
    "initial_channels = 128  # Initial number of channels for CNN\n",
    "start_time=16\n",
    "seq_length = (68 - start_time) * 12  # Number of `5min` windows for 52 hours (624)\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "alpha = 1e-12  # Adjust KL divergence weight\n",
    "patience = 10  # Define the number of epochs without improvement before stopping training\n",
    "padding_method = 'constant'  # Use constant padding\n",
    "is_augment = True  # Enable data augmentation\n",
    "num_good_train=1\n",
    "num_bad_train=1\n",
    "num_good_test=1\n",
    "num_bad_test=1\n",
    "#column_names=['BCI', 'BSAR', 'SIQ', 'SIQ_alpha', 'SIQ_beta', 'SIQ_delta', 'SIQ_theta', 'SignalSD','Prob Seizure','spike hz']\n",
    "column_names=['ssd','BCI','avgspectent', 'lv_l5']\n",
    "#column_names=['BCI','spike hz','meanskewamp']\n",
    "#column_names=['Prob Seizure']\n",
    "#column_names=['meanskewamp']\n",
    "#column_names=['meanlogentropy']\n",
    "#column_names=['avgspectent']\n",
    "\n",
    "\n",
    "num_eeg_channels=len(column_names)\n",
    "\n",
    "is_VAEtrain_aug=False\n",
    "\n",
    "# Define dataset folder paths\n",
    "data_folder = '5min_smoothed_data/'  # Replace with the actual data folder path\n",
    "valid_outcome_data = 'valid_patients_outcome.csv'\n",
    "ssd_file = 'files_art_ssd_fts_predictions.csv'\n",
    "\n",
    "# Create EEG dataset (labels are not used when training VAE)\n",
    "eeg_dataset = EEGDataset(\n",
    "    data_folder='5min_smoothed_data/',\n",
    "    outcome_file='valid_patients_outcome.csv',\n",
    "    ssd_file=ssd_file,\n",
    "    start_time=start_time,\n",
    "    target_length=seq_length,\n",
    "    strategy='padding',\n",
    "    padding_mode=padding_method,\n",
    "    use_labels=True,  # Use labels to determine class-based augmentation\n",
    "    augment=False,  # Enable data augmentation\n",
    "    num_good=1,\n",
    "    num_bad=1,\n",
    "    column_names=column_names\n",
    ")\n",
    "\n",
    "\n",
    "seed_value = 3  \n",
    "torch.manual_seed(seed_value)\n",
    "\n",
    "# **Ê≠•È™§ 1ÔºöÊ£ÄÊü•Êï∞ÊçÆÈõÜ‰∏≠ÁöÑ NaN ÂÄº**\n",
    "def filter_nan_data(dataset):\n",
    "    \"\"\"Á≠õÈÄâÂá∫‰∏çÂåÖÂê´ NaN ÁöÑÊï∞ÊçÆÁ¥¢Âºï\"\"\"\n",
    "    clean_indices = []\n",
    "    nan_indices = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        data, label = dataset[i]  # Ëé∑ÂèñÊï∞ÊçÆÂíåÊ†áÁ≠æ\n",
    "        if torch.isnan(data).any():  # Ê£ÄÊµãÊòØÂê¶ÂåÖÂê´ NaN\n",
    "            nan_indices.append(i)\n",
    "        else:\n",
    "            clean_indices.append(i)\n",
    "    \n",
    "    return clean_indices, nan_indices\n",
    "\n",
    "# Ëé∑ÂèñÊï∞ÊçÆÈõÜ‰∏≠Ê≤°Êúâ NaN ÁöÑÊ†∑Êú¨Á¥¢Âºï\n",
    "clean_indices, nan_indices = filter_nan_data(eeg_dataset)\n",
    "\n",
    "# **Ê≠•È™§ 2ÔºöÈöèÊú∫ÈÄâÊã©‰∏Ä‰∏™‰∏çÂê´ NaN ÁöÑÊ†∑Êú¨**\n",
    "if clean_indices:  # Á°Æ‰øùÊúâÂèØÁî®Êï∞ÊçÆ\n",
    "    selected_index = random.choice(clean_indices)  # ÈöèÊú∫ÈÄâÂèñ‰∏Ä‰∏™Á¥¢Âºï\n",
    "    clean_dataset = Subset(eeg_dataset, [selected_index])  # ÂèñÂá∫ËØ•Ê†∑Êú¨\n",
    "    clean_indices.remove(selected_index)  # ‰ªéÂàóË°®‰∏≠ÁßªÈô§ËØ•Ê†∑Êú¨Á¥¢Âºï\n",
    "else:\n",
    "    clean_dataset = None\n",
    "    print(\"‚ö†Ô∏è Ê≤°ÊúâÊâæÂà∞‰∏çÂê´ NaN ÁöÑÊ†∑Êú¨ÔºÅ\")\n",
    "\n",
    "# **Ê≠•È™§ 3Ôºö‰ªéÂéüÂßãÊï∞ÊçÆÈõÜ‰∏≠ÂéªÈô§Ëøô‰∏™Ê†∑Êú¨**\n",
    "eeg_dataset_1 = Subset(eeg_dataset, nan_indices + clean_indices)  # Âè™‰øùÁïôÂâ©‰ΩôÊï∞ÊçÆ\n",
    "\n",
    "\n",
    "train_size = int(0.8 * len(eeg_dataset_1))\n",
    "test_size = len(eeg_dataset_1) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(eeg_dataset_1, [train_size, test_size])\n",
    "\n",
    "print(f\"Train set size (before augmentation): {len(train_dataset)}\")\n",
    "print(f\"Train set label distribution: {count_labels(train_dataset)}\")  \n",
    "print(f\"Test set size: {len(test_dataset)}\")\n",
    "print(f\"Test set label distribution: {count_labels(test_dataset)}\")  \n",
    "\n",
    "# Augment the training set and the training set respectively\n",
    "augmented_train_dataset = AugmentedEEGDataset(train_dataset, eeg_dataset, augment=is_augment, num_good=num_good_train, num_bad=num_bad_train)\n",
    "augmented_test_dataset = AugmentedEEGDataset(test_dataset, eeg_dataset, augment=is_augment, num_good=num_good_test, num_bad=num_bad_test)\n",
    "\n",
    "# Create DataLoader\n",
    "if is_VAEtrain_aug:\n",
    "    print(\"\\n Augment the training set and the training set respectively:\\n\")\n",
    "    aug_labels = [augmented_train_dataset[i][1] for i in range(len(augmented_train_dataset))]\n",
    "    unique, counts = np.unique(aug_labels, return_counts=True)\n",
    "    print(f\"Train set size (after augmentation): {len(augmented_train_dataset)}\")\n",
    "    print(f\"Train set label distribution (after augmentation): {dict(zip(unique, counts))}\")\n",
    "\n",
    "\n",
    "\n",
    "    aug_labels = [augmented_test_dataset[i][1] for i in range(len(augmented_test_dataset))]\n",
    "    unique, counts = np.unique(aug_labels, return_counts=True)\n",
    "    print(f\"Test set size (after augmentation): {len(augmented_test_dataset)}\")\n",
    "    print(f\"Test set label distribution (after augmentation): {dict(zip(unique, counts))}\")\n",
    "\n",
    "    train_loader = DataLoader(augmented_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(augmented_test_dataset, batch_size=batch_size, shuffle=False)\n",
    "else:\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99d12e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NaNMaskedVAE model\n",
    "class NaNMaskedVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, seq_length):\n",
    "        super(NaNMaskedVAE, self).__init__()\n",
    "        \n",
    "        # Store parameters\n",
    "        self.seq_length = seq_length\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Create separate VAEs for each channel (feature)\n",
    "        self.vaes = nn.ModuleList([SingleChannelVAE(hidden_dim, latent_dim, seq_length) for _ in range(input_dim)])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        recon_x_list, mu_list, logvar_list = [], [], []\n",
    "        \n",
    "        for i in range(self.input_dim):\n",
    "            recon_x, mu, logvar = self.vaes[i](x[:, i, :])  # Process each channel independently\n",
    "            recon_x_list.append(recon_x.unsqueeze(1))  # Add channel dimension back\n",
    "            mu_list.append(mu.unsqueeze(1))\n",
    "            logvar_list.append(logvar.unsqueeze(1))\n",
    "        \n",
    "        recon_x = torch.cat(recon_x_list, dim=1)  # Concatenate along channel dimension\n",
    "        mu = torch.cat(mu_list, dim=1)\n",
    "        logvar = torch.cat(logvar_list, dim=1)\n",
    "        \n",
    "        return recon_x, mu, logvar\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        mu_list = []\n",
    "        for i in range(self.input_dim):\n",
    "            mu = self.vaes[i].get_embedding(x[:, i, :])\n",
    "            mu_list.append(mu.unsqueeze(1))\n",
    "        return torch.cat(mu_list, dim=1)\n",
    "\n",
    "# Define a single-channel VAE for individual features\n",
    "# CNN-based SingleChannelVAE\n",
    "# CNN-based SingleChannelVAE with NaN Masking\n",
    "class SingleChannelVAE(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, seq_length):\n",
    "        super(SingleChannelVAE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Encoder: 1D CNN layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden_dim // 2, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim // 2, hidden_dim, kernel_size=5, stride=2, padding=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mu_layer = nn.Linear(hidden_dim * (seq_length // 4), latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim * (seq_length // 4), latent_dim)\n",
    "\n",
    "        # Decoder: Transposed CNN\n",
    "        self.decoder_fc = nn.Linear(latent_dim, hidden_dim * (seq_length // 4))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(hidden_dim, hidden_dim // 2, kernel_size=5, stride=2, padding=2, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(hidden_dim // 2, 1, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        mask = ~torch.isnan(x)  # Identify valid (non-NaN) data\n",
    "        x_masked = torch.where(mask, x, torch.zeros_like(x))  # Replace NaNs with 0 for CNN processing\n",
    "        x_masked = x_masked.unsqueeze(1)  # Add channel dimension\n",
    "        h = self.encoder(x_masked)\n",
    "        h = self.flatten(h)\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        logvar = torch.clamp(logvar, min=-10, max=10)  # Prevent instability\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = self.decoder_fc(z).view(-1, self.hidden_dim, self.seq_length // 4)\n",
    "        output = self.decoder(h).squeeze(1)\n",
    "        return output  # No NaN replacement here, keeping Masked VAE logic\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z)\n",
    "        return recon_x, mu, logvar\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        mu, _ = self.encode(x)\n",
    "        return mu\n",
    "\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    mask = ~torch.isnan(x)  # True for non-NaN positions\n",
    "    recon_loss = F.mse_loss(recon_x * mask, torch.nan_to_num(x, nan=0.0) * mask, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + alpha * kl_div\n",
    "\n",
    "# Define training function\n",
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = model(x)\n",
    "        loss = loss_function(recon_x, x, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(dataloader.dataset)\n",
    "\n",
    "# Define testing function\n",
    "def test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            recon_x, mu, logvar = model(x)\n",
    "            loss = loss_function(recon_x, x, mu, logvar)\n",
    "            test_loss += loss.item()\n",
    "    return test_loss / len(dataloader.dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6daffe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM_SingleChannelVAE(nn.Module):\n",
    "    def __init__(self, hidden_dim, latent_dim, seq_length, num_states=3, temperature=1.0):\n",
    "        super(HMM_SingleChannelVAE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_states = num_states\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Encoder: 1D Dilated Causal ConvolutionÔºå‰øùÊåÅÂ∫èÂàóÈïøÂ∫¶\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, hidden_dim // 2, kernel_size=3, dilation=1, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim // 2, hidden_dim, kernel_size=3, dilation=1, padding=1, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, dilation=2, padding=2, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # ÂØπÊØè‰∏™Êó∂Èó¥Ê≠•ÁîüÊàêËøûÁª≠ÊΩúÂèòÈáèÂèÇÊï∞\n",
    "        self.mu_layer = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Á¶ªÊï£ÈöêÁä∂ÊÄÅÂàÜÊîØÔºöÊØè‰∏™Êó∂Èó¥Ê≠•ËæìÂá∫ num_states ‰∏™ logits\n",
    "        self.state_classifier = nn.Linear(hidden_dim, num_states)\n",
    "        \n",
    "        # Êñ∞Â¢ûÔºöÂà©Áî® RNN ÊûÑÂª∫Êó∂Â∫èÂÖàÈ™å\n",
    "        # ËæìÂÖ•Â∞∫ÂØ∏‰∏∫ËøûÁª≠ÊΩúÂèòÈáèÂíåÁ¶ªÊï£Áä∂ÊÄÅÊãºÊé•ÂêéÁöÑÁª¥Â∫¶Ôºölatent_dim + num_states\n",
    "        # ËæìÂá∫ÂêåÊ†∑Áª¥Â∫¶ÔºåRNN ËÉΩÂ§üÊçïÊçâ‰∏ä‰∏ãÊñá‰ø°ÊÅØ\n",
    "        self.sequence_prior = nn.LSTM(input_size=latent_dim + num_states,\n",
    "                                      hidden_size=latent_dim + num_states,\n",
    "                                      num_layers=1, batch_first=True)\n",
    "        \n",
    "        # DecoderÔºöÂ∞ÜËûçÂêàÂêéÁöÑÊΩúÂèòÈáèËß£Á†Å\n",
    "        self.decoder_fc = nn.Linear(latent_dim + num_states, hidden_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1)  # ËæìÂá∫Âçï‰∏™Êó∂Èó¥Ê≠•ÈáçÊûÑÂÄº\n",
    "        )\n",
    "    \n",
    "    def gumbel_softmax_sample(self, logits, eps=1e-20):\n",
    "        U = torch.rand_like(logits)\n",
    "        gumbel_noise = -torch.log(-torch.log(U + eps) + eps)\n",
    "        y = logits + gumbel_noise\n",
    "        return F.softmax(y / self.temperature, dim=-1)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        # x: (batch, seq_length)\n",
    "        mask = ~torch.isnan(x)  # True Ë°®Á§∫ÊúâÊïàÊï∞ÊçÆ\n",
    "        x_masked = torch.where(mask, x, torch.zeros_like(x))\n",
    "        x_masked = x_masked.unsqueeze(1)  # (batch, 1, seq_length)\n",
    "        \n",
    "        h = self.encoder(x_masked)  # (batch, hidden_dim, seq_length)\n",
    "        h = h.permute(0, 2, 1)      # (batch, seq_length, hidden_dim)\n",
    "        \n",
    "        # ËøûÁª≠ÊΩúÂèòÈáèÂèÇÊï∞\n",
    "        mu = self.mu_layer(h)         # (batch, seq_length, latent_dim)\n",
    "        logvar = self.logvar_layer(h) # (batch, seq_length, latent_dim)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps * std            # (batch, seq_length, latent_dim)\n",
    "        \n",
    "        # Á¶ªÊï£ÈöêÁä∂ÊÄÅ\n",
    "        state_logits = self.state_classifier(h)  # (batch, seq_length, num_states)\n",
    "        state = self.gumbel_softmax_sample(state_logits)  # (batch, seq_length, num_states)\n",
    "        \n",
    "        return mu, logvar, z, state, mask\n",
    "    \n",
    "    def decode(self, latent_seq):\n",
    "        # latent_seq: (batch, seq_length, latent_dim + num_states)\n",
    "        h_dec = self.decoder_fc(latent_seq)\n",
    "        h_dec = F.relu(h_dec)\n",
    "        recon = self.decoder(h_dec)        # (batch, seq_length, 1)\n",
    "        recon = recon.squeeze(-1)          # (batch, seq_length)\n",
    "        return recon\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_length)\n",
    "        mu, logvar, z, state, mask = self.encode(x)\n",
    "        # ÊãºÊé•ËøûÁª≠ÊΩúÂèòÈáè‰∏éÁ¶ªÊï£Áä∂ÊÄÅÔºàÊØè‰∏™Êó∂Èó¥Ê≠•Ôºâ\n",
    "        latent_combined = torch.cat([z, state], dim=-1)  # (batch, seq_length, latent_dim + num_states)\n",
    "        # ÈÄöËøá RNN ËøõË°å‰∏ä‰∏ãÊñáËûçÂêàÔºåÂæóÂà∞Êó∂Â∫èÂÖàÈ™åËûçÂêàÂêéÁöÑÊΩúÂèòÈáèË°®Á§∫\n",
    "        latent_with_context, _ = self.sequence_prior(latent_combined)  # (batch, seq_length, latent_dim + num_states)\n",
    "        # Ëß£Á†ÅÂô®Ê†πÊçÆËûçÂêàÂêéÁöÑÊΩúÂèòÈáèÁîüÊàêÈáçÊûÑ‰ø°Âè∑\n",
    "        recon_x = self.decode(latent_with_context)\n",
    "        # ÂØπ‰∫éÂÖ®Â±ÄÈöêÂèòÈáèÊèèËø∞ÔºåÂèñÊâÄÊúâÊó∂Èó¥Ê≠•ÁöÑÂπ≥Âùá\n",
    "        mu_avg = mu.mean(dim=1)         # (batch, latent_dim)\n",
    "        logvar_avg = logvar.mean(dim=1) # (batch, latent_dim)\n",
    "        return recon_x, mu_avg, logvar_avg\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        mu, _, _, _, _ = self.encode(x)\n",
    "        return mu.mean(dim=1)\n",
    "\n",
    "# NaNMaskedVAE Áî®‰∫éÂ§ÑÁêÜÂ§öÈÄöÈÅìÊï∞ÊçÆÔºå‰øùÊåÅ‰∏çÂèò\n",
    "class HMM_NaNMaskedVAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim, seq_length, num_states=3, temperature=1.0):\n",
    "        super(HMM_NaNMaskedVAE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.input_dim = input_dim\n",
    "        self.vaes = nn.ModuleList([\n",
    "            HMM_SingleChannelVAE(hidden_dim, latent_dim, seq_length, num_states, temperature)\n",
    "            for _ in range(input_dim)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, input_dim, seq_length)\n",
    "        recon_x_list, mu_list, logvar_list = [], [], []\n",
    "        for i in range(self.input_dim):\n",
    "            recon_x, mu, logvar = self.vaes[i](x[:, i, :])\n",
    "            recon_x_list.append(recon_x.unsqueeze(1))\n",
    "            mu_list.append(mu.unsqueeze(1))\n",
    "            logvar_list.append(logvar.unsqueeze(1))\n",
    "        recon_x = torch.cat(recon_x_list, dim=1)\n",
    "        mu = torch.cat(mu_list, dim=1)\n",
    "        logvar = torch.cat(logvar_list, dim=1)\n",
    "        return recon_x, mu, logvar\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        mu_list = []\n",
    "        for i in range(self.input_dim):\n",
    "            mu = self.vaes[i].get_embedding(x[:, i, :])\n",
    "            mu_list.append(mu.unsqueeze(1))\n",
    "        return torch.cat(mu_list, dim=1)\n",
    "    \n",
    "\n",
    "# ÂÆö‰πâÊçüÂ§±ÂáΩÊï∞Ôºömasked reconstruction loss Âä†‰∏äËøûÁª≠ÈÉ®ÂàÜÁöÑ KL Êï£Â∫¶\n",
    "def HMM_loss_function(recon_x, x, mu, logvar, alpha=1e-12):\n",
    "    # ÊûÑÈÄ† maskÔºàTrue Ë°®Á§∫ÊúâÊïàÊï∞ÊçÆÔºâ\n",
    "    mask = ~torch.isnan(x)\n",
    "    # ËÆ°ÁÆó masked ÁöÑÂùáÊñπËØØÂ∑ÆÔºàÂè™Âú®Èùû NaN ÈÉ®ÂàÜËÆ°ÁÆóËØØÂ∑ÆÔºâ\n",
    "    recon_loss = F.mse_loss(recon_x * mask, torch.nan_to_num(x, nan=0.0) * mask, reduction='sum')\n",
    "    # KL Êï£Â∫¶ÔºàÈíàÂØπËøûÁª≠ÈöêÂèòÈáèÔºâ\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + alpha * kl_div\n",
    "\n",
    "# ËÆ≠ÁªÉÂáΩÊï∞\n",
    "def HMM_train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(dataloader):\n",
    "        x = x.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = model(x)  # Ë∞ÉÁî® HMM-VAE ÁâàÊú¨\n",
    "        loss = HMM_loss_function(recon_x, x, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n",
    "\n",
    "# ÊµãËØïÂáΩÊï∞\n",
    "def HMM_test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            recon_x, mu, logvar = model(x)\n",
    "            loss = HMM_loss_function(recon_x, x, mu, logvar)\n",
    "            total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a43b54",
   "metadata": {},
   "source": [
    "# 1. ÂÖàÂÆö‰πâÂ•Ω NaNMaskedVAE / SingleChannelVAE ‰∏éËÆ≠ÁªÉÊó∂Áõ∏Âêå\n",
    "# 2. ÂÆû‰æãÂåñ‰∏Ä‰∏™Ê®°Âûã\n",
    "cnn_vae_loaded = NaNMaskedVAE(input_dim, hidden_dim, latent_dim, seq_length).to(device)\n",
    "\n",
    "# 3. Âä†ËΩΩ‰øùÂ≠òÁöÑÊùÉÈáç\n",
    "cnn_vae_loaded.load_state_dict(torch.load(\"cnn_vae_final.pth\"))\n",
    "cnn_vae_loaded.eval()\n",
    "\n",
    "HMM_model_loaded = HMM_NaNMaskedVAE(input_dim, hidden_dim, latent_dim, seq_length).to(device)\n",
    "HMM_model_loaded.load_state_dict(torch.load(\"HMM_model_final.pth\"))\n",
    "\n",
    "cnn_vae=cnn_vae_loaded\n",
    "HMM_model=HMM_model_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c14de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Á¨¨‰∏ÄÈò∂ÊÆµÔºöËÆ≠ÁªÉ CNNMaskedVAE Â°´Ë°•Áº∫Â§±Êï∞ÊçÆ\n",
    "##############################################\n",
    "\n",
    "# Êàë‰ª¨ÂÅáËÆæÂ∑≤Êúâ CNNMaskedVAE Âíå NaNMaskedVAEÔºàÂ§öÈÄöÈÅìÂåÖË£ÖÂô®ÔºâÁöÑÂÆö‰πâÔºåËÆ≠ÁªÉÊµÅÁ®ãÂ¶Ç‰∏ãÔºö\n",
    "\n",
    "\n",
    "\n",
    "# ÂàùÂßãÂåñÁî®‰∫éÁº∫Â§±Â°´Ë°•ÁöÑÊ®°ÂûãÔºàCNNMaskedVAE Â∞ÅË£ÖÂú® NaNMaskedVAE ‰∏≠Ôºâ\n",
    "cnn_vae = NaNMaskedVAE(input_dim, hidden_dim, latent_dim, seq_length).to(device)\n",
    "optimizer_cnn = torch.optim.Adam(cnn_vae.parameters(), lr=1e-3)\n",
    "\n",
    "# ËÆ≠ÁªÉ CNN VAEÔºàÂ°´Ë°•Ê®°ÂûãÔºâ\n",
    "best_test_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "train_losses_cnn = []\n",
    "test_losses_cnn = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(cnn_vae, train_loader, optimizer_cnn, device)\n",
    "    test_loss = test(cnn_vae, test_loader, device)\n",
    "    train_losses_cnn.append(train_loss)\n",
    "    test_losses_cnn.append(test_loss)\n",
    "    print(f\"[CNN VAE] Epoch {epoch}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 0\n",
    "        # torch.save(cnn_vae.state_dict(), \"best_cnn_vae.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered for CNN VAE!\")\n",
    "            break\n",
    "\n",
    "# ÂèØÈÄâÔºö‰øùÂ≠òÊàñÁªòÂà∂ËÆ≠ÁªÉÊõ≤Á∫ø\n",
    "plt.plot(train_losses_cnn, label=\"CNN Train Loss\")\n",
    "plt.plot(test_losses_cnn, label=\"CNN Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"CNN VAE Training & Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f75cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Âà©Áî®ËÆ≠ÁªÉÂ•ΩÁöÑ CNNMaskedVAE Â°´Ë°•ÂéüÂßãÊï∞ÊçÆ\n",
    "##############################################\n",
    "def impute_dataset(model, dataset, device):\n",
    "    \"\"\"\n",
    "    ÂØπ dataset ‰∏≠ÁöÑÊØè‰∏™Ê†∑Êú¨ÔºåÁî® model Â°´Ë°•Áº∫Â§±ÂÄºÔºàNaNÔºâÔºåËøîÂõûÊñ∞ÁöÑÊï∞ÊçÆÂàóË°®Ôºå‰øùÊåÅÂéüÊúâÊ†áÁ≠æ„ÄÇ\n",
    "    ËøôÈáåÂØπÊØè‰∏™Ê†∑Êú¨ÔºåÊàë‰ª¨Áî®Ê®°ÂûãÁöÑ forward ËÆ°ÁÆóÈáçÊûÑÁªìÊûúÔºåÁÑ∂ÂêéÔºö\n",
    "      ÂØπÊØè‰∏™‰ΩçÁΩÆÔºöËã•ÂéüÂßãÂÄº‰∏∫ NaNÔºåÂàôÁî®ÈáçÊûÑÂÄºÊõøÊç¢ÔºåÂê¶Âàô‰øùÁïôÂéüÂÄº„ÄÇ\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    imputed_samples = []\n",
    "    for i in range(len(dataset)):\n",
    "        x, label = dataset[i]  # x: (input_dim, seq_length)\n",
    "        x_tensor = x.to(device)\n",
    "        # Â¢ûÂä† batch Áª¥Â∫¶: (1, input_dim, seq_length)\n",
    "        x_tensor = x_tensor.unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            recon, _, _ = model(x_tensor)  # recon: (1, input_dim, seq_length)\n",
    "        # Áî®ÈáçÊûÑÁªìÊûúÂ°´Ë°•Áº∫Â§±ÂÄºÔºötorch.where(Êù°‰ª∂, ÂÄº‰∏∫ True Êó∂, ÂÄº‰∏∫ False Êó∂)\n",
    "        # ËøôÈáåÔºåÊù°‰ª∂‰∏∫ torch.isnan(x_tensor)\n",
    "        x_imputed = torch.where(torch.isnan(x_tensor), recon, x_tensor)\n",
    "        # ÂéªÊéâ batch Áª¥Â∫¶ÔºåÂπ∂ËΩ¨Âõû CPU\n",
    "        imputed_samples.append((x_imputed.squeeze(0).cpu(), label))\n",
    "    return imputed_samples\n",
    "\n",
    "# ‰ΩøÁî®ÂéüÊù•ÁöÑ train_dataset Âíå test_datasetÔºà‰øùÊåÅÊúÄÊó©ÁöÑÂàíÂàÜÔºâ\n",
    "imputed_train_dataset = impute_dataset(cnn_vae, train_dataset, device)\n",
    "imputed_test_dataset = impute_dataset(cnn_vae, test_dataset, device)\n",
    "\n",
    "# ÂàõÂª∫Êñ∞ÁöÑ DataLoaderÔºà‰øùÊåÅÂéüÊù•ÁöÑ batch_sizeÔºâ\n",
    "imputed_train_loader = DataLoader(imputed_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "imputed_test_loader = DataLoader(imputed_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37637e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "# Á¨¨‰∫åÈò∂ÊÆµÔºöÁî®Â°´Ë°•ÂêéÁöÑÊï∞ÊçÆËÆ≠ÁªÉ HMM-VAE Ê®°Âûã\n",
    "##############################################\n",
    "\n",
    "HMM_model = HMM_NaNMaskedVAE(input_dim, hidden_dim, latent_dim, seq_length).to(device)\n",
    "optimizer = torch.optim.Adam(HMM_model.parameters(), lr=1e-3)\n",
    "    \n",
    "# Train and test\n",
    "best_test_loss = float('inf')\n",
    "patience_counter = 0\n",
    "    \n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = HMM_train(HMM_model, imputed_train_loader, optimizer, device)\n",
    "    test_loss = HMM_test(HMM_model, imputed_test_loader, device)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Êó©ÂÅúÈÄªËæë\n",
    "    if test_loss < best_test_loss:\n",
    "        best_test_loss = test_loss\n",
    "        patience_counter = 0\n",
    "        # Â¶ÇÊûúÈúÄË¶ÅÁöÑËØùÔºåÂèØ‰ª•Âú®ËøôÈáå‰øùÂ≠òÊ®°Âûã\n",
    "        # torch.save(model.state_dict(), \"best_model.pth\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "# Plot training curves\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_vae.state_dict(), \"cnn_vae_final.pth\")\n",
    "torch.save(HMM_model.state_dict(), \"HMM_model_final.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490316e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=HMM_model\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "# Â∞Ü train_dataset Âíå test_dataset ÂêàÂπ∂‰∏∫‰∏Ä‰∏™Êï∞ÊçÆÈõÜ\n",
    "combined_dataset = ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# Â¶ÇÊûú‰Ω†ÊÉ≥Áî®‰πãÂâçÁöÑ impute_dataset ÂáΩÊï∞ÂØπÂêàÂπ∂ÂêéÁöÑÊï∞ÊçÆËøõË°åÂ°´Ë°•Ôºö\n",
    "imputed_combined_dataset = impute_dataset(cnn_vae, combined_dataset, device)\n",
    "\n",
    "# ÁÑ∂Âêé‰Ω†ÂèØ‰ª•Áî®Ëøô‰∏™Êñ∞Êï∞ÊçÆÈõÜÂàõÂª∫ DataLoader\n",
    "combined_loader = DataLoader(imputed_combined_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee526d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def check_reconstruction(model, dataloader, device, num_samples=3):\n",
    "    \"\"\"\n",
    "    ÂèØËßÜÂåñ VAE ÁîüÊàêÁöÑ EEG ÈáçÂª∫Êï∞ÊçÆÔºå‰ª•Âèä `latent space`\n",
    "    \n",
    "    ÂèÇÊï∞:\n",
    "    - model: ËÆ≠ÁªÉÂ•ΩÁöÑ VAE Ê®°Âûã\n",
    "    - dataloader: Êï∞ÊçÆÂä†ËΩΩÂô®\n",
    "    - device: ËÆæÂ§áÔºàCPU Êàñ GPUÔºâ\n",
    "    - num_samples: ÈúÄË¶ÅÂèØËßÜÂåñÁöÑÊ†∑Êú¨Êï∞\n",
    "    \"\"\"\n",
    "    model.eval()  # Â∞ÜÊ®°ÂûãËÆæ‰∏∫ËØÑ‰º∞Ê®°Âºè\n",
    "\n",
    "    # Ëé∑Âèñ EEG ÈÄöÈÅìÊï∞\n",
    "    num_channels = dataloader.dataset[0][0].shape[0]  # (num_channels, seq_length)\n",
    "    print(f\"üîç Detected {num_channels} EEG channels.\")\n",
    "\n",
    "    # ÂàõÂª∫ÁîªÂ∏É\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(18, 3 * num_samples))\n",
    "    axes = np.atleast_2d(axes)  # Á°Æ‰øù axes ÊòØ‰∫åÁª¥ÔºåÈÅøÂÖçÂçïÊ†∑Êú¨Êó∂Âá∫Èîô\n",
    "\n",
    "    # ‰ªéÊï∞ÊçÆÂä†ËΩΩÂô®‰∏≠ÈöèÊú∫ÈÄâÊã©‰∏Ä‰∏™ÊâπÊ¨°\n",
    "    for batch_idx, (x, _) in enumerate(dataloader):  # ÂøΩÁï•Ê†áÁ≠æ\n",
    "        x = x.to(device)  # Â∞ÜÊï∞ÊçÆÁßªÂä®Âà∞ËÆæÂ§á‰∏ä\n",
    "\n",
    "        # ÈÄöËøá VAE ËøõË°åÊâπÈáèÈáçÂª∫\n",
    "        with torch.no_grad():\n",
    "            recon_x, mu, _ = model(x)  # Áõ¥Êé•Â§ÑÁêÜÂ§öÈÄöÈÅìÊï∞ÊçÆ\n",
    "\n",
    "        # ÈöèÊú∫ÈÄâÊã©Ê†∑Êú¨ËøõË°åÂèØËßÜÂåñ\n",
    "        indices = torch.randperm(x.size(0))[:num_samples]  # ÈöèÊú∫ÈÄâÊã©Ê†∑Êú¨Á¥¢Âºï\n",
    "        for i, idx in enumerate(indices):\n",
    "            # ÁîüÊàêÊó∂Èó¥ËΩ¥\n",
    "            time_axis = np.linspace(0, (x.shape[2] - 1) * 5 / 60, x.shape[2])\n",
    "\n",
    "            # Ëé∑ÂèñÊâÄÊúâÈÄöÈÅìÁöÑÊúÄÂ∞èÂíåÊúÄÂ§ßÂÄºÔºàÁî®‰∫éÂåπÈÖç y ËΩ¥ËåÉÂõ¥Ôºâ\n",
    "            all_min, all_max = float('inf'), float('-inf')\n",
    "            for ch in range(num_channels):\n",
    "                original_data = x[idx, ch].cpu().numpy()\n",
    "                original_data = np.nan_to_num(original_data, nan=0.0)\n",
    "                all_min = min(all_min, np.min(original_data))\n",
    "                all_max = max(all_max, np.max(original_data))\n",
    "\n",
    "            # **(1) ÂéüÂßã‰ø°Âè∑**\n",
    "            for ch in range(num_channels):\n",
    "                original_data = x[idx, ch].cpu().numpy()\n",
    "                original_data = np.nan_to_num(original_data, nan=0.0)  # Â∞Ü NaN ÊõøÊç¢‰∏∫ 0\n",
    "                \n",
    "                axes[i, 0].plot(time_axis, original_data, label=f\"Ch {ch+1}\", alpha=0.8)\n",
    "            \n",
    "            axes[i, 0].set_title(f\"Sample {i+1} - Original Signal\")\n",
    "            axes[i, 0].set_xlabel(\"Time (hours)\")\n",
    "            axes[i, 0].set_ylabel(\"Amplitude\")\n",
    "            axes[i, 0].legend()\n",
    "            axes[i, 0].grid(True)\n",
    "            axes[i, 0].set_ylim(all_min, all_max)\n",
    "\n",
    "            # **(2) ÈáçÂª∫‰ø°Âè∑**\n",
    "            for ch in range(num_channels):\n",
    "                axes[i, 1].plot(time_axis, recon_x[idx, ch].cpu().numpy().squeeze(),\n",
    "                                label=f\"Ch {ch+1}\", linestyle=\"dashed\", alpha=0.8)\n",
    "            \n",
    "            axes[i, 1].set_title(f\"Sample {i+1} - Reconstructed Signal\")\n",
    "            axes[i, 1].set_xlabel(\"Time (hours)\")\n",
    "            axes[i, 1].set_ylabel(\"Amplitude\")\n",
    "            axes[i, 1].legend()\n",
    "            axes[i, 1].grid(True)\n",
    "            axes[i, 1].set_ylim(all_min, all_max)  # ‰Ωø y ËΩ¥ËåÉÂõ¥‰∏éÂéüÂßã‰ø°Âè∑ÂåπÈÖç\n",
    "\n",
    "            # **(3) Latent Space**\n",
    "            for ch in range(num_channels):\n",
    "                axes[i, 2].bar(range(len(mu[idx, ch].cpu().numpy())), mu[idx, ch].cpu().numpy(), alpha=0.7, label=f\"Ch {ch+1}\")\n",
    "            axes[i, 2].set_title(f\"Sample {i+1} - Latent Space\")\n",
    "            axes[i, 2].set_xlabel(\"Latent Dimension Index\")\n",
    "            axes[i, 2].set_ylabel(\"Value\")\n",
    "            axes[i, 2].legend()\n",
    "            axes[i, 2].grid(True)\n",
    "\n",
    "        break  # Âè™Ê£ÄÊü•‰∏Ä‰∏™ÊâπÊ¨°\n",
    "\n",
    "    # Ë∞ÉÊï¥Â∏ÉÂ±ÄÂπ∂‰øùÂ≠òÂõæÂÉè\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"vae_reconstruction_check.png\")  # ‰øùÂ≠òÂõæÂÉè\n",
    "    plt.show()\n",
    "    \n",
    "# Check reconstruction results\n",
    "check_reconstruction(model, imputed_test_loader, device, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc045e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def extract_latent_features(vae_model, dataset):\n",
    "    \"\"\"\n",
    "    ÊèêÂèñÂ§öÈÄöÈÅì VAE ÁöÑ latent featuresÔºåÂπ∂ËøõË°åÂΩí‰∏ÄÂåñ\n",
    "    \n",
    "    ÂèÇÊï∞:\n",
    "    - vae_model: ËÆ≠ÁªÉÂ•ΩÁöÑÂ§öÈÄöÈÅì VAE\n",
    "    - dataset: EEG Êï∞ÊçÆÈõÜ\n",
    "\n",
    "    ËøîÂõû:\n",
    "    - normalized_latent_features: (batch_size, num_channels * latent_dim) ÂΩí‰∏ÄÂåñÂêéÁöÑÁâπÂæÅ\n",
    "    - labels: Ê†∑Êú¨ÂØπÂ∫îÁöÑÊ†áÁ≠æ\n",
    "    \"\"\"\n",
    "    latent_features = []\n",
    "    labels = []\n",
    "    num_eeg_channels = vae_model.input_dim  # üöÄ Á°Æ‰øù‰∏éÊ®°ÂûãÈÄöÈÅìÊï∞ÂåπÈÖç\n",
    "    \n",
    "    # ËøõÂÖ•ËØÑ‰º∞Ê®°Âºè\n",
    "    vae_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            signal, label = dataset[i]\n",
    "            \n",
    "            if isinstance(signal, torch.Tensor):\n",
    "                signal = signal.to(device)  # üöÄ (num_channels, seq_length)\n",
    "            else:\n",
    "                signal = torch.tensor(signal, dtype=torch.float32).to(device)\n",
    "            \n",
    "            # Ëé∑ÂèñÂ§öÈÄöÈÅì latent vectors\n",
    "            latent_vector = vae_model.get_embedding(signal.unsqueeze(0))  # üöÄ Áõ¥Êé•ÊâπÈáèÊèêÂèñ embedding\n",
    "            \n",
    "            latent_features.append(latent_vector.cpu().numpy().flatten())  # üöÄ ÊãºÊé•ÈÄöÈÅì latent vectors\n",
    "            labels.append(label)\n",
    "    \n",
    "    latent_features = np.array(latent_features)  # üöÄ (num_samples, num_channels * latent_dim)\n",
    "    \n",
    "    # üöÄ **ÂØπ `latent feature` ËøõË°å normalize**\n",
    "    mean = np.mean(latent_features, axis=0, keepdims=True)  # üöÄ ËÆ°ÁÆóÂùáÂÄº\n",
    "    std = np.std(latent_features, axis=0, keepdims=True)  # üöÄ ËÆ°ÁÆóÊ†áÂáÜÂ∑Æ\n",
    "    std[std == 0] = 1e-8  # Èò≤Ê≠¢Èô§‰ª• 0\n",
    "    normalized_latent_features = (latent_features - mean) / std  # üöÄ z-score ÂΩí‰∏ÄÂåñ\n",
    "    \n",
    "    print(f\"‚úÖ Feature extraction complete! Extracted {len(normalized_latent_features)} samples.\")\n",
    "    return normalized_latent_features, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20093b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def extract_latent_features(vae_model, dataset):\n",
    "    \"\"\"\n",
    "    ÊèêÂèñÂ§öÈÄöÈÅì VAE ÁöÑ latent featuresÔºåÂπ∂ÂØπÊØè‰∏™ÈÄöÈÅìÂçïÁã¨ÂΩí‰∏ÄÂåñ\n",
    "    \n",
    "    ÂèÇÊï∞:\n",
    "    - vae_model: ËÆ≠ÁªÉÂ•ΩÁöÑ NaNMaskedVAE\n",
    "    - dataset: EEG Êï∞ÊçÆÈõÜ\n",
    "    - device: ËÆæÂ§áÔºàCPU Êàñ GPUÔºâ\n",
    "\n",
    "    ËøîÂõû:\n",
    "    - normalized_latent_features: (batch_size, num_channels * latent_dim) ÂΩí‰∏ÄÂåñÂêéÁöÑÁâπÂæÅ\n",
    "    - labels: Ê†∑Êú¨ÂØπÂ∫îÁöÑÊ†áÁ≠æ\n",
    "    \"\"\"\n",
    "    latent_features = []\n",
    "    labels = []\n",
    "    num_eeg_channels = vae_model.input_dim  # ÈúÄË¶ÅÂåπÈÖçÊ®°ÂûãÁöÑËæìÂÖ•ÈÄöÈÅìÊï∞\n",
    "\n",
    "    # ËøõÂÖ•ËØÑ‰º∞Ê®°Âºè\n",
    "    vae_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            signal, label = dataset[i]\n",
    "\n",
    "            if isinstance(signal, torch.Tensor):\n",
    "                signal = signal.to(device)  # (num_channels, seq_length)\n",
    "            else:\n",
    "                signal = torch.tensor(signal, dtype=torch.float32).to(device)\n",
    "\n",
    "            # Ëé∑ÂèñÂ§öÈÄöÈÅì latent vectors\n",
    "            latent_vector = vae_model.get_embedding(signal.unsqueeze(0))  # (1, num_channels, latent_dim)\n",
    "\n",
    "            latent_vector = latent_vector.cpu().numpy().squeeze(0)  # (num_channels, latent_dim)\n",
    "\n",
    "            # üöÄ **ÂØπÊØè‰∏™ÈÄöÈÅìÁöÑ latent feature ËøõË°åÁã¨Á´ãÂΩí‰∏ÄÂåñ**\n",
    "            for ch in range(num_eeg_channels):\n",
    "                mean = np.mean(latent_vector[ch], keepdims=True)  # ËÆ°ÁÆóËØ•ÈÄöÈÅìÁöÑÂùáÂÄº\n",
    "                std = np.std(latent_vector[ch], keepdims=True)  # ËÆ°ÁÆóËØ•ÈÄöÈÅìÁöÑÊ†áÂáÜÂ∑Æ\n",
    "                std[std == 0] = 1e-8  # Èò≤Ê≠¢Èô§‰ª• 0\n",
    "\n",
    "                latent_vector[ch] = (latent_vector[ch] - mean) / std  # z-score ÂΩí‰∏ÄÂåñ\n",
    "\n",
    "            # **ÊãºÊé•ÊâÄÊúâÈÄöÈÅìÁöÑÂΩí‰∏ÄÂåñÁâπÂæÅ**\n",
    "            latent_features.append(latent_vector.flatten())  # (num_channels * latent_dim,)\n",
    "            labels.append(label)\n",
    "\n",
    "    # ËΩ¨Êç¢‰∏∫ numpy Êï∞ÁªÑ\n",
    "    normalized_latent_features = np.array(latent_features)  # (num_samples, num_channels * latent_dim)\n",
    "    \n",
    "    print(f\"‚úÖ Feature extraction complete! Extracted {len(normalized_latent_features)} samples.\")\n",
    "\n",
    "    return normalized_latent_features, np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of trained VAE models (one for each EEG channel)\n",
    "vae_models = model # Replace with your trained models\n",
    "\n",
    "# Extract latent features\n",
    "latent_features, labels = extract_latent_features(vae_models, imputed_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# üöÄ 1Ô∏è‚É£ ÂèØËßÜÂåñ `latent feature` ‰Ωú‰∏∫ Heatmap\n",
    "def visualize_latent_heatmap(latent_features, labels):\n",
    "    \"\"\"\n",
    "    Áî® Heatmap ÂèØËßÜÂåñ `latent feature`ÔºåÈÄÇÁî®‰∫éÁõ¥Êé•Êü•ÁúãÁâπÂæÅÂàÜÂ∏É„ÄÇ\n",
    "\n",
    "    ÂèÇÊï∞Ôºö\n",
    "    - latent_features: 2D numpy array, ÂΩ¢Áä∂‰∏∫ (Ê†∑Êú¨Êï∞, ÁâπÂæÅÁª¥Â∫¶)\n",
    "    - labels: 1D numpy array, Ê†∑Êú¨Ê†áÁ≠æ\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(latent_features, cmap='coolwarm', center=0, xticklabels=False, yticklabels=False)\n",
    "    plt.title(\"Latent Feature Heatmap\")\n",
    "    plt.xlabel(\"Latent Dimensions\")\n",
    "    plt.ylabel(\"Samples\")\n",
    "    plt.colorbar(label=\"Feature Value\")\n",
    "    plt.show()\n",
    "\n",
    "# üöÄ 2Ô∏è‚É£ PCA ÈôçÁª¥ + 2D/3D ÂèØËßÜÂåñ\n",
    "def visualize_pca(latent_features, labels, dimensions=2):\n",
    "    \"\"\"\n",
    "    Áî® PCA ÈôçÁª¥ `latent feature` Âπ∂ËøõË°åÂèØËßÜÂåñ„ÄÇ\n",
    "\n",
    "    ÂèÇÊï∞Ôºö\n",
    "    - latent_features: 2D numpy array, ÂΩ¢Áä∂‰∏∫ (Ê†∑Êú¨Êï∞, ÁâπÂæÅÁª¥Â∫¶)\n",
    "    - labels: 1D numpy array, Ê†∑Êú¨Ê†áÁ≠æ\n",
    "    - dimensions: int, ÈôçÁª¥ÁõÆÊ†áÁª¥Â∫¶ (2 Êàñ 3)\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=dimensions)\n",
    "    reduced_features = pca.fit_transform(latent_features)\n",
    "\n",
    "    color_map = {0: 'blue', 1: 'red'}\n",
    "    colors = [color_map[label] for label in labels]\n",
    "\n",
    "    if dimensions == 2:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=colors, alpha=0.7)\n",
    "\n",
    "        handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, alpha=0.7, label='Bad Outcome'),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, alpha=0.7, label='Good Outcome')]\n",
    "        plt.legend(handles=handles, title=\"Labels\")\n",
    "\n",
    "        plt.title(\"PCA Projection of Latent Space (2D)\")\n",
    "        plt.xlabel(\"PCA Component 1\")\n",
    "        plt.ylabel(\"PCA Component 2\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    elif dimensions == 3:\n",
    "        fig = plt.figure(figsize=(10, 8))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        scatter = ax.scatter(reduced_features[:, 0], reduced_features[:, 1], reduced_features[:, 2], c=colors, alpha=0.7)\n",
    "\n",
    "        handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, alpha=0.7, label='Bad Outcome'),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, alpha=0.7, label='Good Outcome')]\n",
    "        ax.legend(handles=handles, title=\"Labels\")\n",
    "        ax.set_title(\"PCA Projection of Latent Space (3D)\")\n",
    "        ax.set_xlabel(\"PCA Component 1\")\n",
    "        ax.set_ylabel(\"PCA Component 2\")\n",
    "        ax.set_zlabel(\"PCA Component 3\")\n",
    "        plt.show()\n",
    "\n",
    "# üöÄ 3Ô∏è‚É£ t-SNE ‰ª£Êõø `UMAP`\n",
    "def visualize_tsne(latent_features, labels, dimensions=2):\n",
    "    \"\"\"\n",
    "    Áî® t-SNE ÈôçÁª¥ `latent feature` Âπ∂ËøõË°åÂèØËßÜÂåñ„ÄÇ\n",
    "\n",
    "    ÂèÇÊï∞Ôºö\n",
    "    - latent_features: 2D numpy array, ÂΩ¢Áä∂‰∏∫ (Ê†∑Êú¨Êï∞, ÁâπÂæÅÁª¥Â∫¶)\n",
    "    - labels: 1D numpy array, Ê†∑Êú¨Ê†áÁ≠æ\n",
    "    - dimensions: int, ÈôçÁª¥ÁõÆÊ†áÁª¥Â∫¶ (2)\n",
    "    \"\"\"\n",
    "    tsne = TSNE(n_components=dimensions, perplexity=30, random_state=42)\n",
    "    reduced_features = tsne.fit_transform(latent_features)\n",
    "\n",
    "    color_map = {0: 'blue', 1: 'red'}\n",
    "    colors = [color_map[label] for label in labels]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=colors, alpha=0.7)\n",
    "\n",
    "    handles = [Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, alpha=0.7, label='Bad Outcome'),\n",
    "               Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, alpha=0.7, label='Good Outcome')]\n",
    "    plt.legend(handles=handles, title=\"Labels\")\n",
    "\n",
    "    plt.title(\"t-SNE Projection of Latent Space (2D)\")\n",
    "    plt.xlabel(\"t-SNE Component 1\")\n",
    "    plt.ylabel(\"t-SNE Component 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a81f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pca(latent_features, labels, dimensions=2)  # `PCA` ÈôçÂà∞ `2D` ÂèØËßÜÂåñ\n",
    "visualize_tsne(latent_features, labels, dimensions=2)  # `t-SNE` Êõø‰ª£ `UMAP` ÂèØËßÜÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ ÊèêÂèñËÆ≠ÁªÉÈõÜÁöÑ `latent feature`\n",
    "X_train, y_train = extract_latent_features(vae_models, imputed_train_dataset)\n",
    "\n",
    "# üöÄ ÊèêÂèñÊµãËØïÈõÜÁöÑ `latent feature`\n",
    "X_test, y_test = extract_latent_features(vae_models, imputed_test_dataset)\n",
    "\n",
    "\n",
    "# üöÄ Á°Æ‰øù labels ÊòØ numpy Êï∞ÁªÑ\n",
    "labels_train = np.array(y_train)\n",
    "labels_test = np.array(y_test)\n",
    "\n",
    "# üöÄ ÊâìÂç∞Á±ªÂà´ÂàÜÂ∏ÉÔºåÊ£ÄÊü•Êï∞ÊçÆÊòØÂê¶Âπ≥Ë°°\n",
    "print(f\"Training set class distribution: {np.bincount(labels_train)}\")\n",
    "print(f\"Testing set class distribution: {np.bincount(labels_test)}\")\n",
    "\n",
    "# üöÄ ÂØπËÆ≠ÁªÉÈõÜËøõË°å SMOTE ËøáÈááÊ†∑Ôºà‰ªÖÂØπËÆ≠ÁªÉÈõÜËøõË°åÊìç‰ΩúÔºåÈÅøÂÖçÊï∞ÊçÆÊ≥ÑÈú≤Ôºâ\n",
    "smote = SMOTE(random_state=42)\n",
    "smote = SMOTE(k_neighbors=2, random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "#X_test, y_test = smote.fit_resample(X_test, y_test)\n",
    "print(f\"Resampled training set class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Resampled training set class distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e163304",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üöÄ **ÂàõÂª∫ XGBoost ÂàÜÁ±ªÊ®°Âûã**\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# üöÄ **ËøõË°åÈ¢ÑÊµã**\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)\n",
    "\n",
    "# üöÄ **ËÆ°ÁÆó AUC ÂíåÂáÜÁ°ÆÁéá**\n",
    "auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb[:, 1])  # Use probability of the positive class\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"‚úÖ XGB Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"‚úÖ XGB AUC: {auc_xgb:.4f}\")\n",
    "print(\"\\n‚úÖ XGB Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"\\n‚úÖ XGB Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n",
    "\n",
    "# üöÄ ‰ΩøÁî® SHAP Ëß£ÈáäÊ®°Âûã\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# üöÄ ÁîªÂá∫ÊâÄÊúâ `latent feature` ÁöÑË¥°ÁåÆ\n",
    "# üöÄ ÂàõÂª∫ `SHAP` Ëß£ÈáäÂô®\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# üöÄ ËÆ°ÁÆó `SHAP` ÂÄº\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "# üöÄ ËÆ°ÁÆóÁâπÂæÅÈáçË¶ÅÊÄßÔºàÂèñ SHAP ÂÄºÁöÑÂπ≥ÂùáÁªùÂØπÂÄºÔºâ\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# üöÄ ÁîüÊàêÁâπÂæÅÂêçÁß∞\n",
    "num_channels = num_eeg_channels  # üöÄ ËøôÈáå‰∏•Ê†ºÈÅµÂÆàÂèòÈáèÂëΩÂêç\n",
    "feature_names = [f\"{column_names[ch]}_Lat{i+1}\" for ch in range(num_channels) for i in range(latent_dim)]\n",
    "\n",
    "# üöÄ Á°Æ‰øù feature_names Áª¥Â∫¶Ê≠£Á°Æ\n",
    "num_features = X_test.shape[1]\n",
    "feature_names = feature_names[:num_features]\n",
    "\n",
    "print(f\"Expected feature count: {num_features}, Generated feature count: {len(feature_names)}\")\n",
    "\n",
    "# üöÄ ÂèØËßÜÂåñ - ÊñπÊ°à 1ÔºöTop 10 ÊúÄÈáçË¶ÅÁöÑ `latent feature`\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]  # ÊåâÁÖßÈáçË¶ÅÊÄßÊéíÂ∫è\n",
    "top_k = 10  # ÂèñÊúÄÈáçË¶ÅÁöÑÂâç 10 ‰∏™ÁâπÂæÅ\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh([feature_names[i] for i in sorted_idx[:top_k]], feature_importance[sorted_idx[:top_k]], color='dodgerblue')\n",
    "plt.xlabel(\"Mean |SHAP Value|\")\n",
    "plt.ylabel(\"Latent Features\")\n",
    "plt.title(\"Top 10 Most Important Latent Features (SHAP)\")\n",
    "plt.gca().invert_yaxis()  # ÂèçËΩ¨ y ËΩ¥Ôºå‰ΩøÊúÄÈáçË¶ÅÁöÑÁâπÂæÅÂú®È°∂ÈÉ®\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "# üöÄ ÂèØËßÜÂåñ - ÊñπÊ°à 2ÔºöÊåâÈÄöÈÅìËÆ°ÁÆóÁâπÂæÅË¥°ÁåÆ\n",
    "channel_importance = [\n",
    "    np.sum(feature_importance[ch * latent_dim : (ch + 1) * latent_dim]) for ch in range(num_channels)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh([f\"{column_names[ch]}\" for ch in range(num_channels)], channel_importance, color=['dodgerblue', 'orangered', 'limegreen'])\n",
    "plt.xlabel(\"Total SHAP Importance\")\n",
    "plt.ylabel(\"EEG Channels\")\n",
    "plt.title(\"Latent Space Contribution by EEG Channel (SHAP)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ËÆ≠ÁªÉ EBM Ê®°Âûã\n",
    "ebm = ExplainableBoostingClassifier(random_state=42)\n",
    "ebm.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ È¢ÑÊµãÁªìÊûú‰∏éÊÄßËÉΩ\n",
    "y_pred_ebm = ebm.predict(X_test)\n",
    "y_pred_proba_ebm = ebm.predict_proba(X_test)\n",
    "\n",
    "auc_ebm = roc_auc_score(y_test, y_pred_proba_ebm[:, 1])\n",
    "accuracy_ebm = accuracy_score(y_test, y_pred_ebm)\n",
    "\n",
    "print(f\"‚úÖ EBM Accuracy: {accuracy_ebm:.4f}\")\n",
    "print(f\"‚úÖ EBM AUC: {auc_ebm:.4f}\")\n",
    "print(\"\\n‚úÖ EBM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_ebm))\n",
    "print(\"\\n‚úÖ EBM Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_ebm))\n",
    "\n",
    "# ‚úÖ ÊèêÂèñÂÖ®Â±ÄËß£ÈáäÊï∞ÊçÆ\n",
    "ebm_global = ebm.explain_global()\n",
    "ebm_feature_names = ebm_global.data()[\"names\"]\n",
    "ebm_importances = ebm_global.data()[\"scores\"]\n",
    "\n",
    "# ‚úÖ ÁîüÊàê‰Ω†ÁöÑÁâπÂæÅÂêç\n",
    "num_features = X_test.shape[1]\n",
    "feature_names = [f\"{column_names[ch]}_Lat{i+1}\" for ch in range(num_eeg_channels) for i in range(latent_dim)]\n",
    "feature_names = feature_names[:num_features]\n",
    "\n",
    "# ‚úÖ Êò†Â∞Ñ EBM feature_0001 -> feature_names[]\n",
    "import re\n",
    "\n",
    "def extract_index(feat_name):\n",
    "    # Âè™ÂåπÈÖçÁ±ª‰ºº \"feature_0032\" ÁöÑÂçï‰∏™ÁâπÂæÅ\n",
    "    match = re.fullmatch(r\"feature_(\\d+)\", feat_name)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None  # ÊòØ‰∫§‰∫íÈ°πÔºåË∑≥Ëøá\n",
    "\n",
    "mapped_names = []\n",
    "mapped_importances = []\n",
    "for feat, score in zip(ebm_feature_names, ebm_importances):\n",
    "    idx = extract_index(feat)\n",
    "    if idx is not None and idx < len(feature_names):\n",
    "        mapped_names.append(feature_names[idx])\n",
    "        mapped_importances.append(score)\n",
    "\n",
    "# ‚úÖ ÂèØËßÜÂåñ Top 10 latent feature\n",
    "sorted_idx = np.argsort(mapped_importances)[::-1]\n",
    "top_k = 10\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(\n",
    "    [mapped_names[i] for i in sorted_idx[:top_k]],\n",
    "    [mapped_importances[i] for i in sorted_idx[:top_k]],\n",
    "    color='mediumseagreen'\n",
    ")\n",
    "plt.xlabel(\"EBM Global Importance Score\")\n",
    "plt.ylabel(\"Latent Features\")\n",
    "plt.title(\"Top 10 Most Important Latent Features (EBM)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "# ‚úÖ ÈÄöÈÅìÁ∫ßÂà´ÁöÑË¥°ÁåÆÊ±áÊÄª\n",
    "channel_importance = [\n",
    "    sum(\n",
    "        mapped_importances[i]\n",
    "        for i in range(len(mapped_names))\n",
    "        if mapped_names[i].startswith(f\"{column_names[ch]}_Lat\")\n",
    "    )\n",
    "    for ch in range(num_eeg_channels)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(\n",
    "    [f\"{column_names[ch]}\" for ch in range(num_eeg_channels)],\n",
    "    channel_importance,\n",
    "    color='coral'\n",
    ")\n",
    "plt.xlabel(\"Total EBM Feature Importance\")\n",
    "plt.ylabel(\"EEG Channels\")\n",
    "plt.title(\"Latent Space Contribution by EEG Channel (EBM)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6509f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ ËÆ≠ÁªÉ CatBoost Ê®°Âûã\n",
    "cat_model = CatBoostClassifier(verbose=0, random_seed=42)\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ È¢ÑÊµã‰∏éËØÑ‰º∞\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "y_pred_proba_cat = cat_model.predict_proba(X_test)\n",
    "\n",
    "auc_cat = roc_auc_score(y_test, y_pred_proba_cat[:, 1])\n",
    "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
    "\n",
    "print(f\"‚úÖ CatBoost Accuracy: {accuracy_cat:.4f}\")\n",
    "print(f\"‚úÖ CatBoost AUC: {auc_cat:.4f}\")\n",
    "print(\"\\n‚úÖ CatBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_cat))\n",
    "print(\"\\n‚úÖ CatBoost Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_cat))\n",
    "\n",
    "# ‚úÖ ËÆ°ÁÆó SHAP ÂÄº\n",
    "explainer = shap.TreeExplainer(cat_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "feature_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# ‚úÖ ÁîüÊàêÁâπÂæÅÂêç\n",
    "num_features = X_test.shape[1]\n",
    "feature_names = [f\"{column_names[ch]}_Lat{i+1}\" for ch in range(num_eeg_channels) for i in range(latent_dim)]\n",
    "feature_names = feature_names[:num_features]\n",
    "\n",
    "# ‚úÖ ÂèØËßÜÂåñ Top 10 ÊúÄÈáçË¶Å latent ÁâπÂæÅ\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "top_k = 10\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(\n",
    "    [feature_names[i] for i in sorted_idx[:top_k]],\n",
    "    feature_importance[sorted_idx[:top_k]],\n",
    "    color='slateblue'\n",
    ")\n",
    "plt.xlabel(\"Mean |SHAP Value|\")\n",
    "plt.ylabel(\"Latent Features\")\n",
    "plt.title(\"Top 10 Most Important Latent Features (CatBoost + SHAP)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()\n",
    "\n",
    "# ‚úÖ ÊåâÈÄöÈÅìËÅöÂêà SHAP Ë¥°ÁåÆ\n",
    "channel_importance = [\n",
    "    np.sum(feature_importance[ch * latent_dim : (ch + 1) * latent_dim])\n",
    "    for ch in range(num_eeg_channels)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.barh(\n",
    "    [column_names[ch] for ch in range(num_eeg_channels)],\n",
    "    channel_importance,\n",
    "    color='salmon'\n",
    ")\n",
    "plt.xlabel(\"Total SHAP Importance\")\n",
    "plt.ylabel(\"EEG Channels\")\n",
    "plt.title(\"Latent Space Contribution by EEG Channel (CatBoost + SHAP)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e412ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_analysis(latent_features, labels, method='kmeans', min_clusters=2, max_clusters=10):\n",
    "    silhouette_scores = []\n",
    "    cluster_models = []\n",
    "\n",
    "    for k in range(min_clusters, max_clusters):\n",
    "        if method == 'kmeans':\n",
    "            model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        elif method == 'gmm':\n",
    "            model = GaussianMixture(n_components=k, random_state=42)\n",
    "        elif method == 'agglo':\n",
    "            model = AgglomerativeClustering(n_clusters=k)\n",
    "        elif method == 'spectral':\n",
    "            model = SpectralClustering(n_clusters=k, assign_labels='kmeans', random_state=42)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported clustering method.\")\n",
    "        \n",
    "        cluster_labels = model.fit_predict(latent_features)\n",
    "        score = silhouette_score(latent_features, cluster_labels)\n",
    "        silhouette_scores.append(score)\n",
    "        cluster_models.append((model, cluster_labels))\n",
    "\n",
    "    optimal_idx = int(np.argmax(silhouette_scores))\n",
    "    optimal_clusters = min_clusters + optimal_idx\n",
    "    best_model, best_labels = cluster_models[optimal_idx]\n",
    "\n",
    "    contingency_table = np.zeros((optimal_clusters, 2))\n",
    "    group_good_bad_ratios = []\n",
    "\n",
    "    for i in range(optimal_clusters):\n",
    "        n_bad = np.sum((best_labels == i) & (labels == 0))\n",
    "        n_good = np.sum((best_labels == i) & (labels == 1))\n",
    "        contingency_table[i, 0] = n_bad\n",
    "        contingency_table[i, 1] = n_good\n",
    "        ratio = n_good / (n_bad + 1e-6)\n",
    "        group_good_bad_ratios.append(ratio)\n",
    "        print(f\"‚úÖ Cluster {i+1}: Good Count = {n_good}, Bad Count = {n_bad}, Good/Bad Ratio = {ratio:.4f}\")\n",
    "\n",
    " \n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    global_good = np.sum(labels == 1)\n",
    "    global_bad = np.sum(labels == 0)\n",
    "    global_ratio = global_good / (global_bad + 1e-6)\n",
    "    t_stat, t_p_value = ttest_ind(group_good_bad_ratios, np.full_like(group_good_bad_ratios, global_ratio))\n",
    "\n",
    "    # Silhouette plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(min_clusters, max_clusters), silhouette_scores, marker='o', linestyle='--', color='b')\n",
    "    plt.axvline(optimal_clusters, linestyle=\"--\", color=\"r\", label=f\"Optimal K = {optimal_clusters}\")\n",
    "    plt.xlabel(\"Number of Clusters\")\n",
    "    plt.ylabel(\"Silhouette Score\")\n",
    "    plt.title(f\"Silhouette Score vs Number of Clusters ({method})\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(contingency_table, annot=True, cmap=\"coolwarm\", fmt=\".0f\",\n",
    "                xticklabels=[\"Bad\", \"Good\"],\n",
    "                yticklabels=[f\"Cluster {i+1}\" for i in range(optimal_clusters)])\n",
    "    plt.xlabel(\"Outcome\")\n",
    "    plt.ylabel(\"Cluster\")\n",
    "    plt.title(\"Outcome Distribution per Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(latent_features)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(optimal_clusters):\n",
    "        mask = best_labels == i\n",
    "        plt.scatter(pca_result[mask, 0], pca_result[mask, 1], label=f\"Cluster {i+1}\", alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"PCA 1\")\n",
    "    plt.ylabel(\"PCA 2\")\n",
    "    plt.title(\"PCA Projection of Clusters\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return best_labels, optimal_clusters, contingency_table, group_good_bad_ratios, global_ratio, chi2, p, dof, expected, t_stat, t_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels, optimal_clusters, contingency_table, group_ratios, global_ratio, chi2, p, dof, expected, t_stat, t_p = run_clustering_analysis(\n",
    "    latent_features, labels, method='kmeans'  # ÊîØÊåÅ 'kmeans', 'gmm', 'agglo', 'spectral'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a258c8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Ëé∑ÂèñÂéüÂßã EEG Êï∞ÊçÆ\n",
    "raw_data = np.array([eeg_dataset_1[i][0].numpy() for i in range(len(eeg_dataset_1))])  # (n_samples, num_channels, time_steps)\n",
    "\n",
    "# **Êó∂Èó¥ËΩ¥Â§ÑÁêÜ**\n",
    "time_per_step = 5/60  # ÊØè‰∏™Êó∂Èó¥Ê≠•‰∏∫ 5 ÂàÜÈíüÔºàÂ∞èÊó∂Ôºâ\n",
    "time_axis = np.arange(raw_data.shape[2]) * time_per_step + start_time\n",
    "\n",
    "# üöÄ ÂÖ®Â±Ä y ËΩ¥ËåÉÂõ¥ÔºàÂè™ÂøΩÁï• NaNÔºâ\n",
    "min_values = np.nanmin(raw_data, axis=(0, 2))\n",
    "max_values = np.nanmax(raw_data, axis=(0, 2))\n",
    "\n",
    "# Â∏ÉÂ±ÄÂèÇÊï∞\n",
    "rows = num_channels + 1                # EEG Â≠êÂõæ + 1 Ë°åÁî®‰∫éÊü±Áä∂Âõæ\n",
    "cols = optimal_clusters\n",
    "height_ratios = [1]*num_channels + [0.5]  # Â∫ïÈÉ®Êü±Áä∂ÂõæË°åÈ´òÂ∫¶ÊòØÂçïË°å EEG ÁöÑ‰∏ÄÂçä\n",
    "\n",
    "fig_width  = 5 * cols\n",
    "fig_height = 5 * num_channels + 3        # È¢ùÂ§ñÁïôÁ∫¶ 3 Ëã±ÂØ∏ÁªôÂ∫ïÈÉ®Êü±Áä∂Âõæ\n",
    "fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "gs = GridSpec(rows, cols, figure=fig,\n",
    "              height_ratios=height_ratios,\n",
    "              hspace=0.4, wspace=0.3)\n",
    "column_names=['Spike Rate', 'BCl', 'Avg Spectral Entropy', 'Voltage Spread']\n",
    "# Good/Bad È¢úËâ≤\n",
    "color_good = '#1974CD'\n",
    "color_bad  = '#FE8000'\n",
    "\n",
    "# ‚Äî EEG Â≠êÂõæ ‚Äî\n",
    "for ch in range(num_channels):\n",
    "    for i in range(cols):\n",
    "        ax = fig.add_subplot(gs[ch, i])\n",
    "        mask = (cluster_labels == i)\n",
    "        # ËÉåÊôØÊ†∑Êú¨Êõ≤Á∫ø\n",
    "        for sample, lab in zip(raw_data[mask, ch, :], labels[mask]):\n",
    "            c = color_good if lab == 1 else color_bad\n",
    "            ax.plot(time_axis, sample, color=c, alpha=0.1)\n",
    "        # ÂùáÂÄºÊõ≤Á∫ø\n",
    "        mean_curve = np.nanmean(raw_data[mask, ch, :], axis=0)\n",
    "        ax.plot(time_axis, mean_curve, color='black', linewidth=2)\n",
    "        # Ê†áÈ¢ò & Ê†áÁ≠æ\n",
    "        ax.set_title(f\"{column_names[ch]} ‚Äì Cluster {i+1}\")\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Amplitude / Value\")\n",
    "        if ch == num_channels - 1:\n",
    "            ax.set_xlabel(\"Time (hours)\")\n",
    "        ax.set_ylim(min_values[ch], max_values[ch])\n",
    "        ax.grid(False)\n",
    "\n",
    "# ‚Äî Â∫ïÈÉ®Â†ÜÂè†Êü±Áä∂ÂõæÔºàË∑®ÊâÄÊúâÂàóÔºâ ‚Äî\n",
    "bar_ax = fig.add_subplot(gs[num_channels, :])\n",
    "good_counts = [int(np.sum((cluster_labels == i) & (labels == 1))) for i in range(cols)]\n",
    "bad_counts  = [int(np.sum((cluster_labels == i) & (labels == 0))) for i in range(cols)]\n",
    "cluster_names = [f\"Cluster {i+1}\" for i in range(cols)]\n",
    "\n",
    "bars_good = bar_ax.bar(cluster_names, good_counts, color=color_good, label='Good Outcome')\n",
    "bars_bad  = bar_ax.bar(cluster_names, bad_counts,  bottom=good_counts, color=color_bad,  label='Bad Outcome')\n",
    "\n",
    "bar_ax.set_xlabel('Cluster')\n",
    "bar_ax.set_ylabel('Number of Samples')\n",
    "bar_ax.set_title('Good vs Bad Outcome Counts per Cluster')\n",
    "bar_ax.legend()\n",
    "bar_ax.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Âú®ÊØè‰∏™Êü±Â≠ê‰∏äÊñπÊ†áÊ≥® ratio\n",
    "# Âú®ÊØè‰∏™Êü±Â≠ê‰∏äÊñπÊ†áÊ≥® ratioÔºàÁ®çÂæÆÈ´ò‰∏ÄÁÇπÔºâ\n",
    "for i, (g, b) in enumerate(zip(good_counts, bad_counts)):\n",
    "    total = g + b\n",
    "    ratio = g / total if total > 0 else 0\n",
    "    y = total * 1.02  # ÊØîÊÄªÈ´òÂ∫¶ÂÜçÂæÄ‰∏ä 2%\n",
    "    bar_ax.text(i, y, f\"{ratio:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa57ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ÂÅáËÆæ latent_features ÁöÑ shape ‰∏∫ (n_samples, num_channels * latent_dim)\n",
    "# column_names: ÂêÑ featureÔºàÂ¶Ç EEG ÈÄöÈÅìÔºâÂêçÁß∞ÂàóË°®\n",
    "# ‰æãÂ¶Ç:\n",
    "#   latent_features = ...  # Â∑≤ÊúâÊï∞ÊçÆÔºåÂΩ¢Áä∂‰∏∫ (n_samples, num_channels * latent_dim)\n",
    "#   column_names = ['Channel1', 'Channel2', 'Channel3']\n",
    "#   latent_dim = 10\n",
    "\n",
    "n_samples, total_dim = latent_features.shape\n",
    "num_channels = len(column_names)\n",
    "latent_dim = total_dim // num_channels\n",
    "\n",
    "# 1. Âà©Áî® PCA Â∞ÜÈ´òÁª¥Êï∞ÊçÆÈôçÂà∞ 2DÔºàÁî®‰∫éÊï¥‰ΩìÊï∞ÊçÆÂàÜÂ∏ÉÂ±ïÁ§∫Ôºâ\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(latent_features)\n",
    "\n",
    "# 2. ÂàõÂª∫Â≠êÂõæÔºåË°åÊï∞ = num_channels, ÂàóÊï∞ = latent_dim\n",
    "fig, axes = plt.subplots(num_channels, latent_dim, figsize=(latent_dim * 4, num_channels * 3), squeeze=False)\n",
    "\n",
    "for ch in range(num_channels):\n",
    "    for ld in range(latent_dim):\n",
    "        # ÂØπ‰∫éÊØè‰∏™ feature ÁöÑÊØè‰∏™ latent Áª¥Â∫¶ÔºåËÆ°ÁÆóÁ¥¢Âºï‰ΩçÁΩÆ\n",
    "        idx = ch * latent_dim + ld\n",
    "        # ÊèêÂèñÂΩìÂâçÁª¥Â∫¶ÁöÑÂÄº\n",
    "        latent_values = latent_features[:, idx]\n",
    "        \n",
    "        # Âú®Êï¥‰Ωì PCA ÂàÜÂ∏É‰∏äÁªòÂà∂Êï£ÁÇπÂõæÔºåÈ¢úËâ≤‰ª£Ë°®ÂΩìÂâç latent Áª¥Â∫¶ÁöÑÂÄº\n",
    "        sc = axes[ch, ld].scatter(X_pca[:, 0], X_pca[:, 1],\n",
    "                                  c=latent_values,\n",
    "                                  cmap='plasma',\n",
    "                                  alpha=0.8,\n",
    "                                  edgecolor='k')\n",
    "        axes[ch, ld].set_title(f\"{column_names[ch]}: latent {ld+1}\")\n",
    "        axes[ch, ld].set_xlabel(\"PC1\")\n",
    "        axes[ch, ld].set_ylabel(\"PC2\")\n",
    "        plt.colorbar(sc, ax=axes[ch, ld], fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccddce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ëé∑ÂèñÊâÄÊúâÂîØ‰∏ÄÁöÑËÅöÁ±ªÊ†áÁ≠æ\n",
    "column_names=['Spike Rate', 'BCI', 'Avg Spectral Entropy', 'Voltage Amplitude']\n",
    "unique_clusters = np.unique(cluster_labels)\n",
    "num_clusters = len(unique_clusters)\n",
    "\n",
    "# ÂàõÂª∫ÂõæÂΩ¢ÔºåÊØè‰∏™Â≠êÂõæÂ±ïÁ§∫‰∏Ä‰∏™Á∞áÁöÑÂπ≥Âùá latent featureÔºà‰ª•ÁÉ≠ÂäõÂõæÂΩ¢ÂºèÔºâ\n",
    "fig, axes = plt.subplots(1, num_clusters, figsize=(5 * num_clusters, 4), squeeze=False)\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, cluster in enumerate(unique_clusters):\n",
    "    # ÊâæÂà∞ÂΩìÂâçÁ∞á‰∏≠ÁöÑÊ†∑Êú¨Á¥¢Âºï\n",
    "    cluster_indices = np.where(cluster_labels == cluster)[0]\n",
    "    # ËÆ°ÁÆóÂΩìÂâçÁ∞á‰∏≠ÊâÄÊúâÊ†∑Êú¨ÁöÑÂπ≥Âùá latent feature\n",
    "    cluster_avg = latent_features[cluster_indices].mean(axis=0)  # shape: (num_channels * latent_dim,)\n",
    "    # Â∞ÜÂπ≥ÂùáÂÄºÈáçÊñ∞ reshape ‰∏∫ (num_channels, latent_dim)\n",
    "    cluster_avg_reshaped = cluster_avg.reshape(num_channels, latent_dim)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    sns.heatmap(cluster_avg_reshaped, ax=ax, cmap='coolwarm', annot=True, fmt=\".2f\")\n",
    "    ax.set_title(f\"Cluster {cluster+1} Mean Latent Feature\")\n",
    "    ax.set_xlabel(\"Latent Dimension\")\n",
    "    ax.set_ylabel(\"Channel\")\n",
    "    # ËÆæÁΩÆ y ËΩ¥ÂàªÂ∫¶Ê†áÁ≠æ‰∏∫ EEG ÈÄöÈÅìÂêçÁß∞\n",
    "    ax.set_yticklabels(column_names, rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
