{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64599e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, Subset, random_split\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "import pywt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import chi2_contingency, ttest_ind\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    silhouette_score,\n",
    ")\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from interpret import show\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c9a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGUtil:\n",
    "    @staticmethod\n",
    "    def load_data(file_path, column_names=['spike hz']):\n",
    "        \"\"\"Load multi-channel EEG data from a CSV file and normalize it.\n",
    "\n",
    "        Parameters:\n",
    "        - file_path: Path to the CSV file.\n",
    "        - column_names: List of EEG signal column names to load.\n",
    "\n",
    "        Returns:\n",
    "        - signal: 2D numpy array (channels √ó time), normalized.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(file_path)\n",
    "\n",
    "        available_columns = [col for col in column_names if col in data.columns]\n",
    "        if not available_columns:\n",
    "            raise ValueError(f\"None of the specified columns {column_names} exist in {file_path}\")\n",
    "\n",
    "        signal = data[available_columns].values.T  # (channels, time)\n",
    "\n",
    "        mean = np.mean(signal, axis=1, keepdims=True)\n",
    "        std = np.std(signal, axis=1, keepdims=True) \n",
    "        std[std == 0] = 1e-8  \n",
    "        \n",
    "        return signal\n",
    "\n",
    "    @staticmethod\n",
    "    def resample(signal: np.ndarray,\n",
    "                 factor: int,\n",
    "                 method: str = 'mean') -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Downsample a multi-channel signal by aggregating each `factor` points into one.\n",
    "    \n",
    "        Args:\n",
    "            signal: 2D array of shape (channels, time).\n",
    "            factor: Number of consecutive points to aggregate (e.g., 12 to go from 5 min to 1 h).\n",
    "            method: Aggregation method‚Äîeither 'mean' or 'sum'.\n",
    "    \n",
    "        Returns:\n",
    "            2D array of shape (channels, time//factor) with aggregated values.\n",
    "    \n",
    "        Note:\n",
    "            This uses NumPy‚Äôs default aggregation behavior. If any NaN values are present\n",
    "            within a group of `factor` points, the result for that group will be NaN.\n",
    "            To ignore NaNs instead, you could replace `reshaped.mean(...)` with\n",
    "            `np.nanmean(reshaped, axis=2)`.\n",
    "        \"\"\"\n",
    "        # Number of EEG channels and original time length\n",
    "        channels, length = signal.shape\n",
    "    \n",
    "        # Determine how many full groups of `factor` fit into the signal\n",
    "        new_length = length // factor\n",
    "    \n",
    "        # Truncate any extra points so length is exactly divisible by factor\n",
    "        trimmed = signal[:, : new_length * factor]\n",
    "    \n",
    "        # Reshape to (channels, new_length, factor) so we can aggregate over the last axis\n",
    "        reshaped = trimmed.reshape(channels, new_length, factor)\n",
    "    \n",
    "        if method == 'mean':\n",
    "            # Compute the average of each group of `factor` points\n",
    "            return reshaped.mean(axis=2)\n",
    "        elif method == 'sum':\n",
    "            # Compute the sum of each group of `factor` points\n",
    "            return reshaped.sum(axis=2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def padding(signal, target_length, mode=\"constant\", constant_value=0):\n",
    "        \"\"\"Pad or truncate multi-channel signal to the target length.\"\"\"\n",
    "        signal = np.array(signal)  # Ensure it's a NumPy array\n",
    "        channels, current_length = signal.shape\n",
    "        \n",
    "        if current_length >= target_length:\n",
    "            return signal[:, :target_length]  # Truncate\n",
    "\n",
    "        padding_size = target_length - current_length\n",
    "        if mode == \"constant\":\n",
    "            pad_values = np.full((channels, padding_size), constant_value)\n",
    "        elif mode == \"reflect\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='reflect')[:, -padding_size:]\n",
    "        elif mode == \"cyclic\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='wrap')[:, -padding_size:]\n",
    "        elif mode == \"edge\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='edge')[:, -padding_size:]\n",
    "        elif mode == \"random\":\n",
    "            pad_values = np.random.uniform(low=np.min(signal), high=np.max(signal), size=(channels, padding_size))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported padding mode: {mode}\")\n",
    "\n",
    "        return np.hstack((signal, pad_values))  # Concatenate along time axis\n",
    "    \n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, data_folder, outcome_file=None, ssd_file=None,start_time=16,target_length=600, strategy='padding', \n",
    "                 padding_mode=\"constant\", use_labels=False, augment=False,num_good=1,num_bad=1,column_names=['spike hz'],time_resolution='5min'):\n",
    "        \n",
    "        \"\"\"\n",
    "        EEG signal datasets with support for data enhancement (random fill). \n",
    "\n",
    "        Parameters: \n",
    "        - data_folder: path of the EEG data folder \n",
    "        - outcome_file: CSV file with patient ID and outcome (optional) \n",
    "        - target_length: indicates the padding length of the target \n",
    "        - strategy: wavelet ('padding', 'wavelet', 'psd') \n",
    "        - padding_mode: indicates the fill mode ('constant', 'reflect',...). \n",
    "        - use_labels: indicates whether to use labels \n",
    "        - augment: Whether data enhancement is enabled (randomly fill different lengths) \n",
    "        \"\"\"\n",
    "\n",
    "        self.use_labels = use_labels\n",
    "        self.data_folder = data_folder\n",
    "        self.target_length = target_length\n",
    "        self.strategy = strategy\n",
    "        self.padding_mode = padding_mode\n",
    "        self.augment = augment \n",
    "        self.column_names = column_names #Feature Chosen\n",
    "        \n",
    "        self.num_good = num_good\n",
    "        self.num_bad = num_bad\n",
    "        \n",
    "        self.start_time=start_time\n",
    "        self.end_time=int((target_length/12)+self.start_time)\n",
    "\n",
    "        self.file_list = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
    "       \n",
    "        # Read 'rosc sec' start time\n",
    "        ssd_df = pd.read_csv(ssd_file)\n",
    "        # Get `pat_ID`\n",
    "        ssd_df[\"pat_ID\"] = ssd_df[\"fn\"].str.extract(r\"(ICARE_\\d+)\")\n",
    "        #  Take the smallest 'rosc sec' of each 'pat ID' \n",
    "        self.rosc_dict = ssd_df.groupby(\"pat_ID\")[\"rosc_sec\"].min().to_dict()\n",
    "        \n",
    "        # LOAD Labels\n",
    "        self.outcome_dict = {}\n",
    "        if use_labels and outcome_file:\n",
    "            self.outcome_data = pd.read_csv(outcome_file)\n",
    "            self.outcome_dict = self.outcome_data.set_index('pat_ID')['outcome'].to_dict()\n",
    "            self.file_list = [f for f in self.file_list if f.split('.')[0] in self.outcome_dict]\n",
    "       \n",
    "        # ËÆ°ÁÆó‰∏ãÈááÊ†∑Âõ†Â≠ê\n",
    "        if time_resolution == '1h':\n",
    "            self.resample_factor = 60 // 5  # 12\n",
    "        else:\n",
    "            self.resample_factor = 1\n",
    "       \n",
    "        self.valid_files = []\n",
    "        # Filter EEG data conforming to 16h-68h rules    \n",
    "        for f in self.file_list:\n",
    "            pat_id = f.split('.')[0]\n",
    "\n",
    "            if pat_id in self.rosc_dict:\n",
    "                file_path = os.path.join(self.data_folder, f)\n",
    "                signal = EEGUtil.load_data(file_path, column_names=self.column_names)  #Load Multiple Channel\n",
    "                rosc_sec = float(self.rosc_dict[pat_id])  # Ensure `rosc_sec` is a float\n",
    "\n",
    "                # **EEG recording time range**\n",
    "                start_time = rosc_sec\n",
    "                end_time = start_time + signal.shape[1] * 300  # Each point represents 5 minutes (=300 seconds)\n",
    "                # **Skip if the data is completely outside the 16h-68h observation window**\n",
    "                if end_time < self.start_time * 3600 or start_time > self.end_time * 3600:\n",
    "                    #print(f\"‚ùå Skipping {pat_id}: EEG data is out of 16h-68h range ({start_time/3600:.1f}h - {end_time/3600:.1f}h)\")\n",
    "                    continue  \n",
    "\n",
    "                # **Align to the 16h-68h window**\n",
    "                aligned_signal = self.align_signal(signal, rosc_sec)\n",
    "                self.valid_files.append((f, aligned_signal))\n",
    "\n",
    "        print(f\"‚úÖ Loaded {len(self.valid_files)} valid EEG files (filtered from {len(self.file_list)} total)\")\n",
    "\n",
    "        # **Count Good/Bad Outcome samples**\n",
    "        self.good_outcome_count = sum(1 for f, _ in self.valid_files if self.get_label(f.split('.')[0]) == 1)\n",
    "        self.bad_outcome_count = len(self.valid_files) - self.good_outcome_count\n",
    "\n",
    "        print(f\"Good Outcome: {self.good_outcome_count}, Bad Outcome: {self.bad_outcome_count}\")\n",
    "\n",
    "        # **Data Augmentation: Expanding indices**\n",
    "        self.expanded_indices = []\n",
    "        for idx, (filename, signal) in enumerate(self.valid_files):\n",
    "            patient_id = filename.split('.')[0]\n",
    "            label = self.get_label(patient_id) if self.use_labels else -1\n",
    "\n",
    "            if self.augment:\n",
    "                if self.use_labels:\n",
    "                    # Good Outcome √ó10, Bad Outcome √ó2\n",
    "                    if label == 1:\n",
    "                        repeat_times = self.num_good\n",
    "                    else:\n",
    "                        repeat_times = self.num_bad\n",
    "                else:\n",
    "                    repeat_times = 1  # Data augmentation for unlabeled data\n",
    "            else:\n",
    "                repeat_times = 1  \n",
    "\n",
    "            for _ in range(repeat_times):\n",
    "                self.expanded_indices.append((idx, label))  # ‚úÖ Store index & label\n",
    "    \n",
    "    def __len__(self):\n",
    "        # print(f\"üìè Dataset __len__: {len(self.expanded_indices)}\")  # Ensure `expanded_indices` length is correct\n",
    "        return len(self.expanded_indices)  # ‚úÖ Must return the number of samples after data augmentation\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        original_idx, label = self.expanded_indices[idx]\n",
    "        filename, signal = self.valid_files[original_idx]  # Directly retrieve the **aligned** signal\n",
    "        patient_id = filename.split('.')[0]\n",
    "\n",
    "        # Get label\n",
    "        label = -1\n",
    "        if self.use_labels:\n",
    "            label = self.get_label(patient_id)\n",
    "\n",
    "        # Perform data augmentation (varies each time)\n",
    "        if self.augment:\n",
    "            augmented_signal = self.augment_signal(signal)  # ‚úÖ Apply augmentation directly to the **aligned signal**\n",
    "        else:\n",
    "            augmented_signal = signal  # ‚úÖ Use the aligned signal directly\n",
    "        \n",
    "        if self.resample_factor > 1:\n",
    "            augmented_signal = EEGUtil.resample(augmented_signal,\n",
    "                                     factor=self.resample_factor,\n",
    "                                     method='mean')\n",
    "\n",
    "        return torch.tensor(augmented_signal, dtype=torch.float32), label\n",
    "    \n",
    "    def align_signal(self, signal, rosc_sec):\n",
    "        \"\"\" Align EEG data to the 16h-68h observation period \"\"\"\n",
    "\n",
    "        target_length = self.target_length  # Number of `5min` windows for 52 hours (624)\n",
    "        total_signal_length = signal.shape[1]  # Total length of the EEG recording\n",
    "        \n",
    "        rosc_sec = float(rosc_sec)  # ‚úÖ Ensure `rosc_sec` is a float\n",
    "        # print(f\"üîç Processing patient data: rosc_sec={rosc_sec}, total_signal_length={total_signal_length}\")\n",
    "\n",
    "        # **Calculate the starting position of '16h' in the EEG recording**\n",
    "        start_sec = (self.start_time * 3600) - rosc_sec  \n",
    "        if start_sec < 0:\n",
    "            pad_size = abs(start_sec) / 300  # Calculate the number of windows to pad\n",
    "            start_index = 0  # Start extracting data from the beginning of the EEG recording\n",
    "        else:\n",
    "            pad_size = 0  # No padding needed\n",
    "            start_index = int(start_sec // 300)  # ‚úÖ Convert to integer\n",
    "\n",
    "        # **Calculate the endpoint index for '68h'**\n",
    "        end_index = int(min(start_index + target_length, total_signal_length))  # ‚úÖ Convert to integer\n",
    "\n",
    "        # **Extract EEG data for the 16h-68h observation period**\n",
    "        aligned_signal = signal[:, start_index:end_index]\n",
    "\n",
    "        # **Pre-padding (if `rosc_sec > 16h`)**\n",
    "        if pad_size > 0:\n",
    "            aligned_signal = EEGDataset.pad_signal(aligned_signal, target_length, self.padding_mode, padding_position=\"pre\")\n",
    "\n",
    "        # **Post-padding (if data is less than 52 hours)**\n",
    "        aligned_signal = EEGDataset.pad_signal(aligned_signal, target_length, self.padding_mode, padding_position=\"post\")\n",
    "\n",
    "        # print(f\"‚úÖ Aligned signal length: {len(aligned_signal)}\")\n",
    "        return aligned_signal\n",
    "    \n",
    "    def pad_signal(signal, target_length, mode=\"constant\", constant_value=0, padding_position=\"post\"):\n",
    "        \"\"\" Pad EEG signal to ensure it reaches `target_length`.\n",
    "\n",
    "        Parameters:\n",
    "        - signal: Original EEG signal (numpy array)\n",
    "        - target_length: Target length (52h = 624 `5min` windows)\n",
    "        - mode: Padding mode:\n",
    "            - `constant`: Fill with a fixed value (`constant_value`)\n",
    "            - `reflect`: Mirror padding\n",
    "            - `cyclic`: Cyclic padding\n",
    "            - `edge`: Edge padding\n",
    "            - `random`: Fill with random values between [min, max]\n",
    "        - padding_position: `\"pre\"` (pad at the beginning) or `\"post\"` (pad at the end)\n",
    "\n",
    "        Returns:\n",
    "        - Padded EEG signal (numpy array)\n",
    "        \"\"\"\n",
    "\n",
    "        channels, current_length = signal.shape\n",
    "        \n",
    "        if current_length >= target_length:\n",
    "            return signal[:, :target_length]  # Truncate if already long enough\n",
    "\n",
    "        padding_size = target_length - current_length  # Number of elements to pad\n",
    "\n",
    "        if mode == \"constant\":\n",
    "            pad_values = np.full((channels, padding_size), constant_value)  # Make sure padding shape matches\n",
    "        elif mode == \"reflect\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='reflect')[:, -padding_size:]\n",
    "        elif mode == \"cyclic\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='wrap')[:, -padding_size:]\n",
    "        elif mode == \"edge\":\n",
    "            pad_values = np.pad(signal, ((0, 0), (0, padding_size)), mode='edge')[:, -padding_size:]\n",
    "        elif mode == \"random\":\n",
    "            pad_values = np.random.uniform(low=np.min(signal), high=np.max(signal), size=(channels, padding_size))\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported padding mode: {mode}\")\n",
    "\n",
    "        # Ensure proper concatenation along the time axis\n",
    "        if padding_position == \"pre\":\n",
    "            padded_signal = np.hstack((pad_values, signal))  # Pad at the beginning\n",
    "        else:\n",
    "            padded_signal = np.hstack((signal, pad_values))  # Pad at the end\n",
    "\n",
    "        return padded_signal[:, :target_length]  # Ensure exact target length\n",
    "    \n",
    "    def augment_signal(self, signal):\n",
    "        \"\"\" Data augmentation: Shift EEG data within the 16h-68h observation period \"\"\"\n",
    "\n",
    "        target_length = self.target_length  # Number of `5min` windows for 52 hours (624)\n",
    "        channels, current_length = signal.shape  # Current EEG recording length\n",
    "\n",
    "        # **Check if already aligned to 16h-68h before augmentation**\n",
    "        if current_length != target_length:\n",
    "            raise ValueError(f\"Before augmentation, signal length should be {target_length}, but received {current_length}\")\n",
    "\n",
    "        # **Augmentation Strategy 1: Random time shift within ¬±60min**\n",
    "        max_shift = 12  # `5min` windows, 60 minutes = 12 data points\n",
    "        shift = np.random.randint(-max_shift, max_shift + 1)  # Random shift in [-12, 12]\n",
    "\n",
    "        # **Compute new starting index and ensure it remains within bounds**\n",
    "        start_index = max(0, min(current_length - target_length, shift))\n",
    "        end_index = min(start_index + target_length, current_length)\n",
    "\n",
    "        # **Extract EEG data after shifting**\n",
    "        augmented_signal = signal[:, start_index:end_index]\n",
    "\n",
    "        # **Augmentation Strategy 2: Apply padding based on `shift` direction**\n",
    "        if augmented_signal.shape[1] < target_length:\n",
    "            padding_size = target_length - augmented_signal.shape[1]\n",
    "\n",
    "            if shift > 0:\n",
    "                pad_values = self.pad_signal(np.zeros((channels, padding_size)), target_length, self.padding_mode)\n",
    "                augmented_signal = np.hstack((pad_values, augmented_signal))  # **Á°Æ‰øùÂΩ¢Áä∂Ê≠£Á°Æ**\n",
    "            elif shift < 0:\n",
    "                pad_values = self.pad_signal(np.zeros((channels, padding_size)), target_length, self.padding_mode)\n",
    "                augmented_signal = np.hstack((augmented_signal, pad_values))\n",
    "            else:\n",
    "                augmented_signal = self.pad_signal(augmented_signal, target_length, self.padding_mode)\n",
    "\n",
    "        return augmented_signal\n",
    "\n",
    "    def get_label(self, patient_id):\n",
    "        \"\"\" Get sample label (1 = Good Outcome, 0 = Bad Outcome) \"\"\"\n",
    "        return 1 if self.outcome_dict.get(patient_id, 'Bad Outcome') == 'Good Outcome' else 0\n",
    "\n",
    "    def compare_data_augmentation(self):\n",
    "        \"\"\" Compare the number of samples before and after data augmentation. \"\"\"\n",
    "        original_count = len(self.valid_files)  # Count only files that meet the 16h condition\n",
    "        augmented_count = len(self.expanded_indices)  # Count the number of augmented samples\n",
    "\n",
    "        print(f\"Data count before augmentation: {original_count}\")\n",
    "        print(f\"Data count after augmentation: {augmented_count}\")\n",
    "        print(f\"Augmentation ratio: {augmented_count / original_count:.2f}x\")\n",
    "\n",
    "        if self.use_labels:\n",
    "            # Count Good Outcome and Bad Outcome samples in original data (filtered_files)\n",
    "            good_outcome_original = sum(1 for f, _ in self.valid_files if self.get_label(f.split('.')[0]) == 1)\n",
    "            bad_outcome_original = original_count - good_outcome_original  # Remaining are Bad Outcome samples\n",
    "\n",
    "            # Count Good Outcome and Bad Outcome samples after augmentation\n",
    "            good_outcome_augmented = sum(\n",
    "                1 for (idx, _) in self.expanded_indices  # ‚úÖ Use only idx, ignore label\n",
    "                if self.get_label(self.valid_files[idx][0].split('.')[0]) == 1\n",
    "            )\n",
    "            bad_outcome_augmented = augmented_count - good_outcome_augmented  # Remaining are Bad Outcome samples\n",
    "\n",
    "            print(f\"Good Outcome before augmentation: {good_outcome_original}, after augmentation: {good_outcome_augmented}\")\n",
    "            print(f\"Bad Outcome before augmentation: {bad_outcome_original}, after augmentation: {bad_outcome_augmented}\")\n",
    "\n",
    "        return original_count, augmented_count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a7ba6a7-6b24-4139-ac90-ac3b88a62de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ñ∂Ô∏è ÊúÄÁªàÁî®‰Ωú column_names ÁöÑÊï∞ÂÄºÂûãÂàó (ÂÖ± 95 Âàó)Ôºö\n",
      "['BCI', 'BSAR', 'SIQ', 'SIQ_alpha', 'SIQ_beta', 'SIQ_delta', 'SIQ_theta', 'SignalSD', 'alphakurtosis', 'alphameanrat', 'alphaminrat', 'alphapctrat', 'alphastdrat', 'avgspectent', 'avgspectkurt', 'betakurtosis', 'betameanrat', 'betaminrat', 'betapctrat', 'betastdrat', 'corrmean', 'd0MaxAmp', 'd0MaxMaxFourAmp', 'd0MeanMaxAmp', 'd0MeanMaxFourAmp', 'd0MeanVarAmp', 'd0VarMaxAmp', 'd0VarMaxFourAmp', 'd0VarMeanAmp', 'd0VarVarAmp', 'd1MaxAmp', 'd1MaxMaxFourAmp', 'd1MeanMaxAmp', 'd1MeanMaxFourAmp', 'd1MeanVarAmp', 'd1VarMaxAmp', 'd1VarMaxFourAmp', 'd1VarMeanAmp', 'd1VarVarAmp', 'd2MaxAmp', 'd2MaxMaxFourAmp', 'd2MeanMaxAmp', 'd2MeanMaxFourAmp', 'd2MeanVarAmp', 'd2VarMaxAmp', 'd2VarMaxFourAmp', 'd2VarMeanAmp', 'd2VarVarAmp', 'deltaalphamean', 'deltaalphamin', 'deltaalphapct', 'deltaalphastd', 'deltakurtosis', 'deltameanrat', 'deltaminrat', 'deltapctrat', 'deltastdrat', 'deltathetamean', 'deltathetamin', 'deltathetapct', 'deltathetastd', 'geomeanamp', 'harmmeanamp', 'kurtavg', 'linelengthmean', 'lv_l10', 'lv_l20', 'lv_l5', 'meaniqrchannelamp', 'meanlogentropy', 'meanrms', 'meanskewamp', 'nleavgstd', 'nlemean', 'overalliqramp', 'overallskewamp', 'pctchangepoint', 'pctpeakpoint', 'sdrms', 'sdspectent', 'sdspectkurt', 'shanavg', 'ssd', 'stdskewamp', 'thetaalphamean', 'thetaalphamin', 'thetaalphapct', 'thetaalphastd', 'thetakurtosis', 'thetameanrat', 'thetaminrat', 'thetapctrat', 'thetastdrat', 'xcorrmean', 'xcorrstd']\n"
     ]
    }
   ],
   "source": [
    "data_folder = '5min_smoothed_data/'  # Êç¢Êàê‰Ω†ÁöÑË∑ØÂæÑ\n",
    "\n",
    "# ‚Äî‚Äî 1. Êâ´ÊèèÊâÄÊúâ CSV Êñá‰ª∂ÔºåÊî∂ÈõÜÂàóÂêçÂπ∂ÂéªÊéâ cpc ‚Äî‚Äî \n",
    "all_columns = set()\n",
    "for fname in os.listdir(data_folder):\n",
    "    if fname.endswith('.csv'):\n",
    "        df0 = pd.read_csv(os.path.join(data_folder, fname), nrows=0)\n",
    "        all_columns.update(df0.columns.tolist())\n",
    "cols = sorted(all_columns)\n",
    "for drop in ['cpc', 'pat_ID', 'timestamp_hour']:\n",
    "    if drop in cols:\n",
    "        cols.remove(drop)\n",
    "\n",
    "# ‚Äî‚Äî 2. ‰ªéÁ§∫‰æãÊñá‰ª∂Á≠õÈÄâÊï∞ÂÄºÂûãÂàó ‚Äî‚Äî \n",
    "example_csv = next(f for f in os.listdir(data_folder) if f.endswith('.csv'))\n",
    "example_df  = pd.read_csv(os.path.join(data_folder, example_csv), nrows=10)\n",
    "\n",
    "numeric_cols = [\n",
    "    col for col in cols\n",
    "    if pd.api.types.is_numeric_dtype(example_df[col])\n",
    "]\n",
    "\n",
    "print(\"‚ñ∂Ô∏è ÊúÄÁªàÁî®‰Ωú column_names ÁöÑÊï∞ÂÄºÂûãÂàó (ÂÖ± {} Âàó)Ôºö\".format(len(numeric_cols)))\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11c61b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "‚úÖ Loaded 244 valid EEG files (filtered from 244 total)\n",
      "Good Outcome: 44, Bad Outcome: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# ‚Äî‚Äî 0. ËÆæÂ§áËÆæÁΩÆ ‚Äî‚Äî \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# ‚Äî‚Äî 1. Ë∂ÖÂèÇÊï∞‰∏éÊï∞ÊçÆÈõÜÂàùÂßãÂåñ ‚Äî‚Äî \n",
    "start_time   = 16\n",
    "seq_length   = (68 - start_time) * 12  # 624 ‰∏™ 5min Á™óÂè£\n",
    "#column_names = ['ssd', 'BCI', 'avgspectent', 'lv_l5']\n",
    "column_names = numeric_cols\n",
    "#column_names = ['BCI']\n",
    "batch_size   = 32\n",
    "epochs       = 100\n",
    "n_splits     = 5\n",
    "learning_rate= 1e-3\n",
    "time_resolution='1h'   # Êñ∞Â¢ûÂèÇÊï∞Ôºö'5min' Êàñ '1h'\n",
    "\n",
    "\n",
    "# ÂàõÂª∫ EEGDataset\n",
    "eeg_dataset = EEGDataset(\n",
    "    data_folder='5min_smoothed_data/',\n",
    "    outcome_file='valid_patients_outcome.csv',\n",
    "    ssd_file='files_art_ssd_fts_predictions.csv',\n",
    "    start_time=start_time,\n",
    "    target_length=seq_length,\n",
    "    strategy='padding',\n",
    "    padding_mode='constant',\n",
    "    use_labels=True,\n",
    "    augment=False,\n",
    "    num_good=1,\n",
    "    num_bad=1,\n",
    "    column_names=column_names,\n",
    "    time_resolution=time_resolution\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3adaf704-c9e2-4505-a545-c1eea040b099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After downsample: X.shape=(244, 52, 95), y.shape=(244,), group count=244\n",
      "Warning: X ‰∏≠Â≠òÂú®Êó†ÊïàÂÄºÔºÅ\n",
      "  NaN count: 16464\n",
      "  Inf count: 0\n",
      "Âê´ NaN ÁöÑÊ†∑Êú¨Á¥¢ÂºïÔºö [  1   2   7  13  15  17  18  21  23  24  25  27  28  29  30  31  32  33\n",
      "  35  41  42  44  45  46  49  50  52  54  55  56  59  60  61  62  69  70\n",
      "  71  73  74  77  78  79  80  81  82  85  86  87  88  89  92  94  96 100\n",
      " 103 106 107 108 109 111 112 115 116 117 118 119 121 124 125 129 130 132\n",
      " 133 136 138 139 140 142 143 144 146 147 148 149 150 152 153 154 155 156\n",
      " 157 160 162 163 164 165 168 169 170 171 174 177 178 179 182 183 186 187\n",
      " 188 192 193 199 203 204 206 207 209 212 214 215 216 217 219 222 223 225\n",
      " 226 227 228 229 230 231 233 234 235 238 239 242 243]\n",
      "Â°´ÂÖÖÂêéÔºöNaN count = 0 Inf count = 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "signals, labels, groups = [], [], []\n",
    "for i in range(len(eeg_dataset)):\n",
    "    sig_tensor, lab = eeg_dataset[i]        # ÊØèÊ¨°Âè™Êúâ ~1 ms\n",
    "    signals.append(sig_tensor.numpy().T)    # (T', C)\n",
    "    labels.append(lab)\n",
    "    pid = eeg_dataset.valid_files[\n",
    "              eeg_dataset.expanded_indices[i][0]\n",
    "          ][0].split('.')[0]\n",
    "    groups.append(pid)\n",
    "\n",
    "X = np.stack(signals, dtype=np.float32)    # (244, T', C)\n",
    "y = np.array(labels, dtype=np.float32)\n",
    "\n",
    "# ‚Äî‚Äî 3. ÈáçÂª∫ groups ÂàóË°® ‚Äî‚Äî \n",
    "# Áî±‰∫é DataLoader shuffle=FalseÔºåÊ†∑Êú¨È°∫Â∫èÁ≠âÂêå‰∫é eeg_dataset.expanded_indices È°∫Â∫è\n",
    "groups = [\n",
    "    eeg_dataset.valid_files[e_idx][0].split('.')[0]\n",
    "    for e_idx, _ in eeg_dataset.expanded_indices\n",
    "]\n",
    "\n",
    "print(f\"After downsample: X.shape={X.shape}, y.shape={y.shape}, group count={len(groups)}\")\n",
    "\n",
    "# ‚Äî‚Äî 4. Ê£ÄÊµã NaN / Inf ‚Äî‚Äî \n",
    "if np.isnan(X).any() or np.isinf(X).any():\n",
    "    print(\"Warning: X ‰∏≠Â≠òÂú®Êó†ÊïàÂÄºÔºÅ\")\n",
    "    print(\"  NaN count:\", np.isnan(X).sum())\n",
    "    print(\"  Inf count:\", np.isinf(X).sum())\n",
    "\n",
    "nan_idxs = np.unique(np.where(np.isnan(X))[0])\n",
    "print(\"Âê´ NaN ÁöÑÊ†∑Êú¨Á¥¢ÂºïÔºö\", nan_idxs)\n",
    "\n",
    "# ÂèØËßÜÂåñÂåÖÂê´ NaN ÁöÑÊ†∑Êú¨\n",
    "if False:\n",
    "    for idx in nan_idxs:\n",
    "        series = X[idx]          # shape = (T', C)\n",
    "        Tprime, C = series.shape\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        for c in range(C):\n",
    "            plt.plot(series[:, c], label=f\"feat{c}\")\n",
    "            nan_pos = np.where(np.isnan(series[:, c]))[0]\n",
    "            plt.scatter(nan_pos, np.zeros_like(nan_pos), marker='x')\n",
    "        plt.title(f\"Sample {idx} with NaN\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "# ‚Äî‚Äî 5. Áî® 0 Â°´ÂÖÖ NaN Âíå Inf ‚Äî‚Äî \n",
    "X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "print(\"Â°´ÂÖÖÂêéÔºöNaN count =\", np.isnan(X).sum(),\n",
    "      \"Inf count =\", np.isinf(X).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4963cf5c-f75d-43be-b93d-e58188f269f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      " train balance: Counter({0.0: 162, 1.0: 33})\n",
      "  test balance: Counter({0.0: 38, 1.0: 11})\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 3s - 124ms/step - accuracy: 0.7692 - auc: 0.5178 - loss: 0.5702\n",
      "Epoch 2/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8205 - auc: 0.5932 - loss: 0.4597\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.8308 - auc: 0.6110 - loss: 0.4461\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.8256 - auc: 0.6222 - loss: 0.4453\n",
      "Epoch 5/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8308 - auc: 0.6870 - loss: 0.4231\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8410 - auc: 0.6442 - loss: 0.4327\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8462 - auc: 0.6958 - loss: 0.4135\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 29ms/step - accuracy: 0.8513 - auc: 0.7811 - loss: 0.3818\n",
      "Epoch 9/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8513 - auc: 0.8035 - loss: 0.3733\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.8462 - auc: 0.8393 - loss: 0.3565\n",
      "Epoch 11/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8513 - auc: 0.7417 - loss: 0.3902\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.8513 - auc: 0.7854 - loss: 0.3671\n",
      "Epoch 13/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8667 - auc: 0.8588 - loss: 0.3354\n",
      "Epoch 14/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8769 - auc: 0.7924 - loss: 0.3538\n",
      "Epoch 15/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8821 - auc: 0.8763 - loss: 0.3125\n",
      "Epoch 16/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.8718 - auc: 0.8173 - loss: 0.3430\n",
      "Epoch 17/20\n",
      "25/25 - 1s - 24ms/step - accuracy: 0.8923 - auc: 0.8721 - loss: 0.3062\n",
      "Epoch 18/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8872 - auc: 0.8848 - loss: 0.2996\n",
      "Epoch 19/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.8923 - auc: 0.8685 - loss: 0.3119\n",
      "Epoch 20/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.9026 - auc: 0.8937 - loss: 0.2836\n",
      "Accuracy: 75.51%, AUC: 57.30%\n",
      "\n",
      "--- Fold 2 ---\n",
      " train balance: Counter({0.0: 161, 1.0: 34})\n",
      "  test balance: Counter({0.0: 39, 1.0: 10})\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 124ms/step - accuracy: 0.6923 - auc: 0.5194 - loss: 0.6093\n",
      "Epoch 2/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8205 - auc: 0.5495 - loss: 0.4782\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8256 - auc: 0.6041 - loss: 0.4594\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.8256 - auc: 0.6039 - loss: 0.4550\n",
      "Epoch 5/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8256 - auc: 0.5466 - loss: 0.4681\n",
      "Epoch 6/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8308 - auc: 0.6732 - loss: 0.4359\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8410 - auc: 0.7114 - loss: 0.4126\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8462 - auc: 0.6900 - loss: 0.4159\n",
      "Epoch 9/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8513 - auc: 0.7171 - loss: 0.4099\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.8667 - auc: 0.7276 - loss: 0.3995\n",
      "Epoch 11/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8615 - auc: 0.7815 - loss: 0.3679\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8769 - auc: 0.7624 - loss: 0.3643\n",
      "Epoch 13/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8667 - auc: 0.6935 - loss: 0.4046\n",
      "Epoch 14/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8718 - auc: 0.7302 - loss: 0.3831\n",
      "Epoch 15/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8821 - auc: 0.8138 - loss: 0.3354\n",
      "Epoch 16/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.9026 - auc: 0.8426 - loss: 0.3125\n",
      "Epoch 17/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8923 - auc: 0.8560 - loss: 0.3153\n",
      "Epoch 18/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8769 - auc: 0.8355 - loss: 0.3224\n",
      "Epoch 19/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8769 - auc: 0.8706 - loss: 0.3024\n",
      "Epoch 20/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.9026 - auc: 0.8791 - loss: 0.2881\n",
      "Accuracy: 73.47%, AUC: 46.54%\n",
      "\n",
      "--- Fold 3 ---\n",
      " train balance: Counter({0.0: 161, 1.0: 34})\n",
      "  test balance: Counter({0.0: 39, 1.0: 10})\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 124ms/step - accuracy: 0.8051 - auc: 0.5933 - loss: 0.5318\n",
      "Epoch 2/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8205 - auc: 0.6084 - loss: 0.4626\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.8205 - auc: 0.5488 - loss: 0.4707\n",
      "Epoch 4/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8308 - auc: 0.6338 - loss: 0.4489\n",
      "Epoch 5/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8308 - auc: 0.6355 - loss: 0.4354\n",
      "Epoch 6/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8359 - auc: 0.6474 - loss: 0.4261\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8564 - auc: 0.7169 - loss: 0.4051\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.8513 - auc: 0.6720 - loss: 0.4156\n",
      "Epoch 9/20\n",
      "25/25 - 1s - 25ms/step - accuracy: 0.8513 - auc: 0.7002 - loss: 0.4000\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8615 - auc: 0.7511 - loss: 0.3878\n",
      "Epoch 11/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8667 - auc: 0.7673 - loss: 0.3748\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8667 - auc: 0.7669 - loss: 0.3682\n",
      "Epoch 13/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8974 - auc: 0.7934 - loss: 0.3415\n",
      "Epoch 14/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8923 - auc: 0.8024 - loss: 0.3332\n",
      "Epoch 15/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.9077 - auc: 0.7850 - loss: 0.3453\n",
      "Epoch 16/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8872 - auc: 0.8627 - loss: 0.3048\n",
      "Epoch 17/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.9026 - auc: 0.8507 - loss: 0.3004\n",
      "Epoch 18/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.9026 - auc: 0.8309 - loss: 0.3018\n",
      "Epoch 19/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.9026 - auc: 0.8096 - loss: 0.3028\n",
      "Epoch 20/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.7949 - auc: 0.8266 - loss: 0.3913\n",
      "Accuracy: 73.47%, AUC: 53.97%\n",
      "\n",
      "--- Fold 4 ---\n",
      " train balance: Counter({0.0: 157, 1.0: 38})\n",
      "  test balance: Counter({0.0: 43, 1.0: 6})\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 128ms/step - accuracy: 0.7590 - auc: 0.4162 - loss: 0.5994\n",
      "Epoch 2/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8000 - auc: 0.5342 - loss: 0.5056\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8051 - auc: 0.6461 - loss: 0.4765\n",
      "Epoch 4/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8051 - auc: 0.6130 - loss: 0.4795\n",
      "Epoch 5/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8051 - auc: 0.6457 - loss: 0.4737\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8051 - auc: 0.6975 - loss: 0.4602\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8051 - auc: 0.6649 - loss: 0.4646\n",
      "Epoch 8/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8051 - auc: 0.6961 - loss: 0.4616\n",
      "Epoch 9/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8051 - auc: 0.6848 - loss: 0.4461\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8051 - auc: 0.7107 - loss: 0.4535\n",
      "Epoch 11/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8103 - auc: 0.7166 - loss: 0.4393\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8205 - auc: 0.7549 - loss: 0.4215\n",
      "Epoch 13/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8308 - auc: 0.7271 - loss: 0.4181\n",
      "Epoch 14/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8513 - auc: 0.7465 - loss: 0.4157\n",
      "Epoch 15/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8410 - auc: 0.7544 - loss: 0.4068\n",
      "Epoch 16/20\n",
      "25/25 - 0s - 18ms/step - accuracy: 0.8667 - auc: 0.7886 - loss: 0.3884\n",
      "Epoch 17/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8462 - auc: 0.7205 - loss: 0.4187\n",
      "Epoch 18/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8564 - auc: 0.7726 - loss: 0.4014\n",
      "Epoch 19/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8615 - auc: 0.7928 - loss: 0.3823\n",
      "Epoch 20/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8718 - auc: 0.7799 - loss: 0.3760\n",
      "Accuracy: 85.71%, AUC: 51.16%\n",
      "\n",
      "--- Fold 5 ---\n",
      " train balance: Counter({0.0: 159, 1.0: 37})\n",
      "  test balance: Counter({0.0: 41, 1.0: 7})\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 134ms/step - accuracy: 0.6888 - auc: 0.4842 - loss: 0.6452\n",
      "Epoch 2/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8163 - auc: 0.4799 - loss: 0.5220\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8112 - auc: 0.5048 - loss: 0.4962\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8112 - auc: 0.4962 - loss: 0.4967\n",
      "Epoch 5/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8112 - auc: 0.5752 - loss: 0.4755\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8163 - auc: 0.6044 - loss: 0.4721\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8163 - auc: 0.5456 - loss: 0.4773\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8163 - auc: 0.5778 - loss: 0.4661\n",
      "Epoch 9/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8214 - auc: 0.6055 - loss: 0.4617\n",
      "Epoch 10/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8214 - auc: 0.7199 - loss: 0.4351\n",
      "Epoch 11/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.8265 - auc: 0.6024 - loss: 0.4608\n",
      "Epoch 12/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8265 - auc: 0.6470 - loss: 0.4474\n",
      "Epoch 13/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8214 - auc: 0.7007 - loss: 0.4397\n",
      "Epoch 14/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8316 - auc: 0.7580 - loss: 0.4161\n",
      "Epoch 15/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.8316 - auc: 0.6708 - loss: 0.4334\n",
      "Epoch 16/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.8469 - auc: 0.7379 - loss: 0.4160\n",
      "Epoch 17/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8469 - auc: 0.7392 - loss: 0.4167\n",
      "Epoch 18/20\n",
      "25/25 - 0s - 18ms/step - accuracy: 0.8418 - auc: 0.7765 - loss: 0.4065\n",
      "Epoch 19/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8418 - auc: 0.7390 - loss: 0.4126\n",
      "Epoch 20/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8265 - auc: 0.7155 - loss: 0.4323\n",
      "Accuracy: 85.42%, AUC: 59.06%\n",
      "\n",
      "=== Cross‚ÄêValidation Results ===\n",
      "Mean Accuracy: 78.72% ¬± 5.64%\n",
      "Mean AUC     : 53.61% ¬± 4.46%\n"
     ]
    }
   ],
   "source": [
    "# ‚Äî‚Äî 2. ËÆæÁΩÆ‰∫§ÂèâÈ™åËØÅÂíå‰øùÂ≠òÁªìÊûúÁöÑÂÆπÂô® ‚Äî‚Äî \n",
    "cv        = GroupKFold(n_splits=5)\n",
    "cvscores  = []\n",
    "auc_scores= []\n",
    "preds_all = []\n",
    "\n",
    "# ‚Äî‚Äî 3. Âú®ÊØè‰∏™ fold ‰∏≠ÈáçÊñ∞ÊûÑÂª∫Ê®°Âûã„ÄÅËÆ≠ÁªÉ„ÄÅËØÑ‰º∞ ‚Äî‚Äî \n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx], y[test_idx]\n",
    "    \n",
    "    print(\" train balance:\", Counter(y_tr))\n",
    "    print(\"  test balance:\", Counter(y_te))\n",
    "    \n",
    "    # ‚Äî‚Äî 3.1 ÂÆö‰πâ Keras Ê®°Âûã ‚Äî‚Äî \n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(12, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    # ‚Äî‚Äî 3.2 ËÆ≠ÁªÉ ‚Äî‚Äî \n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        batch_size=8,\n",
    "        epochs=20,    # ÂèØË∞ÉÊï¥\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # ‚Äî‚Äî 3.3 ËØÑ‰º∞ ‚Äî‚Äî \n",
    "    scores = model.evaluate(X_te, y_te, verbose=0)\n",
    "    acc    = scores[1] * 100\n",
    "    auc    = scores[2] * 100\n",
    "    print(f\"Accuracy: {acc:.2f}%, AUC: {auc:.2f}%\")\n",
    "    \n",
    "    # ‚Äî‚Äî 3.4 ‰øùÂ≠òÁªìÊûú ‚Äî‚Äî \n",
    "    cvscores.append(acc)\n",
    "    auc_scores.append(auc)\n",
    "    \n",
    "    # ‚Äî‚Äî 3.5 È¢ÑÊµãÂπ∂Â≠òÂÇ®ÊâÄÊúâ fold ÁöÑËæìÂá∫ ‚Äî‚Äî \n",
    "    preds = model.predict(X_te, verbose=0).flatten()\n",
    "    preds_all.extend(preds)\n",
    "\n",
    "# ‚Äî‚Äî 4. Ê±áÊÄªÊâÄÊúâ fold ‚Äî‚Äî \n",
    "print(\"\\n=== Cross‚ÄêValidation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(cvscores):.2f}% ¬± {np.std(cvscores):.2f}%\")\n",
    "print(f\"Mean AUC     : {np.mean(auc_scores):.2f}% ¬± {np.std(auc_scores):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e762c9d4-e0b6-4c91-ae4b-407f71b53dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      " train balance: Counter({0.0: 162, 1.0: 33})\n",
      "  test balance: Counter({0.0: 38, 1.0: 11})\n",
      " class weights: {0.0: 0.6018518518518519, 1.0: 2.9545454545454546}\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 132ms/step - accuracy: 0.2308 - auc: 0.4740 - loss: 0.7404\n",
      "Epoch 2/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.3128 - auc: 0.5711 - loss: 0.7102\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.2974 - auc: 0.5415 - loss: 0.7199\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.3385 - auc: 0.5105 - loss: 0.7181\n",
      "Epoch 5/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.3641 - auc: 0.5632 - loss: 0.6976\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.4308 - auc: 0.5618 - loss: 0.6945\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.4615 - auc: 0.5580 - loss: 0.6927\n",
      "Epoch 8/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.4154 - auc: 0.5403 - loss: 0.6948\n",
      "Epoch 9/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.4513 - auc: 0.6158 - loss: 0.6725\n",
      "Epoch 10/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.4718 - auc: 0.5374 - loss: 0.6912\n",
      "Epoch 11/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.4769 - auc: 0.5421 - loss: 0.6940\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5179 - auc: 0.5303 - loss: 0.6917\n",
      "Epoch 13/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.5026 - auc: 0.5780 - loss: 0.6720\n",
      "Epoch 14/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.6103 - auc: 0.6494 - loss: 0.6566\n",
      "Epoch 15/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.4974 - auc: 0.5731 - loss: 0.6758\n",
      "Epoch 16/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.5282 - auc: 0.5468 - loss: 0.6776\n",
      "Epoch 17/20\n",
      "25/25 - 0s - 18ms/step - accuracy: 0.5795 - auc: 0.6004 - loss: 0.6654\n",
      "Epoch 18/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.5846 - auc: 0.6313 - loss: 0.6574\n",
      "Epoch 19/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.5590 - auc: 0.5825 - loss: 0.6750\n",
      "Epoch 20/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5590 - auc: 0.6296 - loss: 0.6569\n",
      "Accuracy: 73.47%, AUC: 70.45%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step\n",
      "\n",
      "--- Fold 2 ---\n",
      " train balance: Counter({0.0: 161, 1.0: 34})\n",
      "  test balance: Counter({0.0: 39, 1.0: 10})\n",
      " class weights: {0.0: 0.6055900621118012, 1.0: 2.8676470588235294}\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 130ms/step - accuracy: 0.7538 - auc: 0.5132 - loss: 0.7610\n",
      "Epoch 2/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.7538 - auc: 0.5686 - loss: 0.7307\n",
      "Epoch 3/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.7538 - auc: 0.5308 - loss: 0.7408\n",
      "Epoch 4/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.7538 - auc: 0.5632 - loss: 0.7237\n",
      "Epoch 5/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.7846 - auc: 0.6081 - loss: 0.7026\n",
      "Epoch 6/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.7795 - auc: 0.5823 - loss: 0.7120\n",
      "Epoch 7/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.7897 - auc: 0.6355 - loss: 0.6932\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.7897 - auc: 0.6177 - loss: 0.6969\n",
      "Epoch 9/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.7846 - auc: 0.5614 - loss: 0.7090\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.7846 - auc: 0.6458 - loss: 0.6871\n",
      "Epoch 11/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8103 - auc: 0.6057 - loss: 0.6937\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.8154 - auc: 0.5891 - loss: 0.6983\n",
      "Epoch 13/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8000 - auc: 0.6004 - loss: 0.6925\n",
      "Epoch 14/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.7897 - auc: 0.6538 - loss: 0.6766\n",
      "Epoch 15/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.8154 - auc: 0.6968 - loss: 0.6663\n",
      "Epoch 16/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8205 - auc: 0.6948 - loss: 0.6641\n",
      "Epoch 17/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8000 - auc: 0.7007 - loss: 0.6655\n",
      "Epoch 18/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8205 - auc: 0.7088 - loss: 0.6619\n",
      "Epoch 19/20\n",
      "25/25 - 0s - 18ms/step - accuracy: 0.8205 - auc: 0.7284 - loss: 0.6561\n",
      "Epoch 20/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.8410 - auc: 0.7530 - loss: 0.6498\n",
      "Accuracy: 71.43%, AUC: 48.97%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "\n",
      "--- Fold 3 ---\n",
      " train balance: Counter({0.0: 161, 1.0: 34})\n",
      "  test balance: Counter({0.0: 39, 1.0: 10})\n",
      " class weights: {0.0: 0.6055900621118012, 1.0: 2.8676470588235294}\n",
      "Epoch 1/20\n",
      "25/25 - 5s - 184ms/step - accuracy: 0.4205 - auc: 0.5038 - loss: 0.6945\n",
      "Epoch 2/20\n",
      "25/25 - 1s - 29ms/step - accuracy: 0.4718 - auc: 0.5434 - loss: 0.6897\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5231 - auc: 0.5928 - loss: 0.6820\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.5026 - auc: 0.5727 - loss: 0.6842\n",
      "Epoch 5/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.5026 - auc: 0.5346 - loss: 0.6902\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.5538 - auc: 0.5406 - loss: 0.6938\n",
      "Epoch 7/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5641 - auc: 0.6008 - loss: 0.6759\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.5641 - auc: 0.5673 - loss: 0.6844\n",
      "Epoch 9/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5179 - auc: 0.5577 - loss: 0.6837\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 22ms/step - accuracy: 0.5897 - auc: 0.6339 - loss: 0.6712\n",
      "Epoch 11/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.6051 - auc: 0.6085 - loss: 0.6719\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 22ms/step - accuracy: 0.5795 - auc: 0.5906 - loss: 0.6744\n",
      "Epoch 13/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5949 - auc: 0.6431 - loss: 0.6685\n",
      "Epoch 14/20\n",
      "25/25 - 1s - 22ms/step - accuracy: 0.6000 - auc: 0.6126 - loss: 0.6746\n",
      "Epoch 15/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.6154 - auc: 0.6335 - loss: 0.6664\n",
      "Epoch 16/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.6308 - auc: 0.6092 - loss: 0.6728\n",
      "Epoch 17/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.6667 - auc: 0.6721 - loss: 0.6568\n",
      "Epoch 18/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.6308 - auc: 0.6189 - loss: 0.6669\n",
      "Epoch 19/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.6154 - auc: 0.6146 - loss: 0.6635\n",
      "Epoch 20/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.6256 - auc: 0.6062 - loss: 0.6645\n",
      "Accuracy: 59.18%, AUC: 46.79%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step\n",
      "\n",
      "--- Fold 4 ---\n",
      " train balance: Counter({0.0: 157, 1.0: 38})\n",
      "  test balance: Counter({0.0: 43, 1.0: 6})\n",
      " class weights: {0.0: 0.6210191082802548, 1.0: 2.5657894736842106}\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 130ms/step - accuracy: 0.6205 - auc: 0.5312 - loss: 0.6945\n",
      "Epoch 2/20\n",
      "25/25 - 1s - 30ms/step - accuracy: 0.6974 - auc: 0.6211 - loss: 0.6786\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 25ms/step - accuracy: 0.6256 - auc: 0.5462 - loss: 0.6873\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.6821 - auc: 0.5695 - loss: 0.6981\n",
      "Epoch 5/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.6513 - auc: 0.6081 - loss: 0.6779\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.6462 - auc: 0.5814 - loss: 0.6834\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.6718 - auc: 0.6337 - loss: 0.6735\n",
      "Epoch 8/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.6923 - auc: 0.5999 - loss: 0.6832\n",
      "Epoch 9/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.6103 - auc: 0.5682 - loss: 0.6887\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.6667 - auc: 0.6781 - loss: 0.6604\n",
      "Epoch 11/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.6872 - auc: 0.6408 - loss: 0.6718\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.6410 - auc: 0.6109 - loss: 0.6747\n",
      "Epoch 13/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.6205 - auc: 0.5981 - loss: 0.6771\n",
      "Epoch 14/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.7128 - auc: 0.6839 - loss: 0.6591\n",
      "Epoch 15/20\n",
      "25/25 - 0s - 20ms/step - accuracy: 0.6410 - auc: 0.6219 - loss: 0.6725\n",
      "Epoch 16/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.6974 - auc: 0.7370 - loss: 0.6464\n",
      "Epoch 17/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.6718 - auc: 0.6618 - loss: 0.6659\n",
      "Epoch 18/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.6462 - auc: 0.6710 - loss: 0.6562\n",
      "Epoch 19/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.6769 - auc: 0.6626 - loss: 0.6617\n",
      "Epoch 20/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.6769 - auc: 0.7057 - loss: 0.6477\n",
      "Accuracy: 69.39%, AUC: 54.65%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step\n",
      "\n",
      "--- Fold 5 ---\n",
      " train balance: Counter({0.0: 159, 1.0: 37})\n",
      "  test balance: Counter({0.0: 41, 1.0: 7})\n",
      " class weights: {0.0: 0.6163522012578616, 1.0: 2.6486486486486487}\n",
      "Epoch 1/20\n",
      "25/25 - 3s - 128ms/step - accuracy: 0.2092 - auc: 0.5074 - loss: 0.7614\n",
      "Epoch 2/20\n",
      "25/25 - 1s - 29ms/step - accuracy: 0.2347 - auc: 0.5445 - loss: 0.7385\n",
      "Epoch 3/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.2806 - auc: 0.5000 - loss: 0.7360\n",
      "Epoch 4/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.3112 - auc: 0.6202 - loss: 0.7042\n",
      "Epoch 5/20\n",
      "25/25 - 1s - 25ms/step - accuracy: 0.3520 - auc: 0.6345 - loss: 0.6926\n",
      "Epoch 6/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.3163 - auc: 0.4765 - loss: 0.7267\n",
      "Epoch 7/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.3571 - auc: 0.5623 - loss: 0.6984\n",
      "Epoch 8/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.3469 - auc: 0.5792 - loss: 0.6926\n",
      "Epoch 9/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.3776 - auc: 0.5976 - loss: 0.6847\n",
      "Epoch 10/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.3827 - auc: 0.6034 - loss: 0.6832\n",
      "Epoch 11/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.4235 - auc: 0.6293 - loss: 0.6795\n",
      "Epoch 12/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.4490 - auc: 0.6368 - loss: 0.6741\n",
      "Epoch 13/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.4337 - auc: 0.6169 - loss: 0.6768\n",
      "Epoch 14/20\n",
      "25/25 - 1s - 20ms/step - accuracy: 0.4796 - auc: 0.6119 - loss: 0.6772\n",
      "Epoch 15/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5051 - auc: 0.6719 - loss: 0.6676\n",
      "Epoch 16/20\n",
      "25/25 - 1s - 27ms/step - accuracy: 0.5561 - auc: 0.7121 - loss: 0.6539\n",
      "Epoch 17/20\n",
      "25/25 - 0s - 19ms/step - accuracy: 0.5204 - auc: 0.6190 - loss: 0.6763\n",
      "Epoch 18/20\n",
      "25/25 - 1s - 28ms/step - accuracy: 0.5102 - auc: 0.6277 - loss: 0.6726\n",
      "Epoch 19/20\n",
      "25/25 - 1s - 26ms/step - accuracy: 0.5102 - auc: 0.6302 - loss: 0.6731\n",
      "Epoch 20/20\n",
      "25/25 - 1s - 21ms/step - accuracy: 0.5510 - auc: 0.6203 - loss: 0.6747\n",
      "Accuracy: 41.67%, AUC: 54.01%\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 238ms/step\n",
      "\n",
      "=== Cross‚ÄêValidation Results ===\n",
      "Mean Accuracy: 63.03% ¬± 11.76%\n",
      "Mean AUC     : 54.98% ¬± 8.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Dense\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "# ÂÅáËÆæ X, y, groups ÈÉΩÂ∑≤ÂáÜÂ§áÂ•Ω\n",
    "cv = GroupKFold(n_splits=5)\n",
    "cvscores, auc_scores, preds_all = [], [], []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx], y[test_idx]\n",
    "    print(\" train balance:\", Counter(y_tr))\n",
    "    print(\"  test balance:\", Counter(y_te))\n",
    "    \n",
    "    # ËÆ°ÁÆóÁ±ªÂà´ÊùÉÈáç\n",
    "    classes = np.unique(y_tr)\n",
    "    weights = compute_class_weight('balanced', classes=classes, y=y_tr)\n",
    "    class_weight = dict(zip(classes, weights))\n",
    "    print(\" class weights:\", class_weight)\n",
    "    \n",
    "    # ÂÆö‰πâÊ®°Âûã\n",
    "    model = Sequential([\n",
    "        Input(shape=(X.shape[1], X.shape[2])),\n",
    "        LSTM(64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(12),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipnorm=1.0),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "    \n",
    "    # ËÆ≠ÁªÉÊó∂‰º†ÂÖ• class_weight\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        batch_size=8,\n",
    "        epochs=20,\n",
    "        verbose=2,\n",
    "        class_weight=class_weight\n",
    "    )\n",
    "    \n",
    "    # ËØÑ‰º∞\n",
    "    loss, acc, auc = model.evaluate(X_te, y_te, verbose=0)\n",
    "    print(f\"Accuracy: {acc*100:.2f}%, AUC: {auc*100:.2f}%\")\n",
    "    cvscores.append(acc*100)\n",
    "    auc_scores.append(auc*100)\n",
    "    \n",
    "    preds_all.extend(model.predict(X_te).flatten())\n",
    "\n",
    "# Ê±áÊÄª\n",
    "print(\"\\n=== Cross‚ÄêValidation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(cvscores):.2f}% ¬± {np.std(cvscores):.2f}%\")\n",
    "print(f\"Mean AUC     : {np.mean(auc_scores):.2f}% ¬± {np.std(auc_scores):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ba6b528-d212-4885-90ae-fc75748ccc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Fold 1 ---\n",
      " train balance: Counter({0.0: 162, 1.0: 33})\n",
      "  test balance: Counter({0.0: 38, 1.0: 11})\n",
      " after oversampling: Counter({0.0: 162, 1.0: 162})\n",
      "Epoch 1/20\n",
      "41/41 - 5s - 111ms/step - accuracy: 0.5123 - auc: 0.4611 - loss: 0.0832\n",
      "Epoch 2/20\n",
      "41/41 - 1s - 36ms/step - accuracy: 0.5000 - auc: 0.5163 - loss: 0.0772\n",
      "Epoch 3/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.5031 - auc: 0.5341 - loss: 0.0759\n",
      "Epoch 4/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.4877 - auc: 0.5512 - loss: 0.0750\n",
      "Epoch 5/20\n",
      "41/41 - 1s - 32ms/step - accuracy: 0.4969 - auc: 0.5633 - loss: 0.0730\n",
      "Epoch 6/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.5093 - auc: 0.5905 - loss: 0.0712\n",
      "Epoch 7/20\n",
      "41/41 - 1s - 32ms/step - accuracy: 0.5216 - auc: 0.6148 - loss: 0.0696\n",
      "Epoch 8/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.5247 - auc: 0.6176 - loss: 0.0698\n",
      "Epoch 9/20\n",
      "41/41 - 1s - 32ms/step - accuracy: 0.5123 - auc: 0.6649 - loss: 0.0663\n",
      "Epoch 10/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.5154 - auc: 0.6391 - loss: 0.0679\n",
      "Epoch 11/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.5340 - auc: 0.6554 - loss: 0.0661\n",
      "Epoch 12/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.5586 - auc: 0.6957 - loss: 0.0623\n",
      "Epoch 13/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.5617 - auc: 0.6627 - loss: 0.0648\n",
      "Epoch 14/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.5772 - auc: 0.7176 - loss: 0.0605\n",
      "Epoch 15/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.5802 - auc: 0.7261 - loss: 0.0597\n",
      "Epoch 16/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.6080 - auc: 0.7222 - loss: 0.0593\n",
      "Epoch 17/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.6389 - auc: 0.7470 - loss: 0.0556\n",
      "Epoch 18/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.6173 - auc: 0.7487 - loss: 0.0566\n",
      "Epoch 19/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.6481 - auc: 0.7819 - loss: 0.0526\n",
      "Epoch 20/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.6698 - auc: 0.7856 - loss: 0.0523\n",
      "Accuracy: 73.47%, AUC: 67.94%\n",
      "\n",
      "--- Fold 2 ---\n",
      " train balance: Counter({0.0: 161, 1.0: 34})\n",
      "  test balance: Counter({0.0: 39, 1.0: 10})\n",
      " after oversampling: Counter({0.0: 161, 1.0: 161})\n",
      "Epoch 1/20\n",
      "41/41 - 5s - 111ms/step - accuracy: 0.4938 - auc: 0.5051 - loss: 0.0924\n",
      "Epoch 2/20\n",
      "41/41 - 1s - 35ms/step - accuracy: 0.5217 - auc: 0.5350 - loss: 0.0832\n",
      "Epoch 3/20\n",
      "41/41 - 1s - 32ms/step - accuracy: 0.5342 - auc: 0.5781 - loss: 0.0770\n",
      "Epoch 4/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.5714 - auc: 0.6071 - loss: 0.0721\n",
      "Epoch 5/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5652 - auc: 0.6488 - loss: 0.0683\n",
      "Epoch 6/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.5839 - auc: 0.6438 - loss: 0.0677\n",
      "Epoch 7/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.6025 - auc: 0.6978 - loss: 0.0629\n",
      "Epoch 8/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.5932 - auc: 0.7269 - loss: 0.0600\n",
      "Epoch 9/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.6429 - auc: 0.7866 - loss: 0.0545\n",
      "Epoch 10/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.6366 - auc: 0.7763 - loss: 0.0538\n",
      "Epoch 11/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.6615 - auc: 0.7959 - loss: 0.0506\n",
      "Epoch 12/20\n",
      "41/41 - 1s - 21ms/step - accuracy: 0.7019 - auc: 0.8030 - loss: 0.0493\n",
      "Epoch 13/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.7267 - auc: 0.8144 - loss: 0.0473\n",
      "Epoch 14/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.7174 - auc: 0.8112 - loss: 0.0461\n",
      "Epoch 15/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.7236 - auc: 0.8128 - loss: 0.0455\n",
      "Epoch 16/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.7857 - auc: 0.8488 - loss: 0.0407\n",
      "Epoch 17/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.7733 - auc: 0.8586 - loss: 0.0386\n",
      "Epoch 18/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.7702 - auc: 0.8364 - loss: 0.0401\n",
      "Epoch 19/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.8106 - auc: 0.8536 - loss: 0.0375\n",
      "Epoch 20/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.7826 - auc: 0.8526 - loss: 0.0374\n",
      "Accuracy: 77.55%, AUC: 45.64%\n",
      "\n",
      "--- Fold 3 ---\n",
      " train balance: Counter({0.0: 161, 1.0: 34})\n",
      "  test balance: Counter({0.0: 39, 1.0: 10})\n",
      " after oversampling: Counter({0.0: 161, 1.0: 161})\n",
      "Epoch 1/20\n",
      "41/41 - 5s - 111ms/step - accuracy: 0.5000 - auc: 0.5156 - loss: 0.0864\n",
      "Epoch 2/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.5186 - auc: 0.5228 - loss: 0.0803\n",
      "Epoch 3/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.5186 - auc: 0.5217 - loss: 0.0782\n",
      "Epoch 4/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.5342 - auc: 0.6167 - loss: 0.0707\n",
      "Epoch 5/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5342 - auc: 0.6287 - loss: 0.0681\n",
      "Epoch 6/20\n",
      "41/41 - 1s - 32ms/step - accuracy: 0.5435 - auc: 0.6849 - loss: 0.0646\n",
      "Epoch 7/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5404 - auc: 0.6408 - loss: 0.0675\n",
      "Epoch 8/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.5621 - auc: 0.6485 - loss: 0.0660\n",
      "Epoch 9/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5528 - auc: 0.6595 - loss: 0.0654\n",
      "Epoch 10/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5652 - auc: 0.7014 - loss: 0.0616\n",
      "Epoch 11/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5745 - auc: 0.6838 - loss: 0.0625\n",
      "Epoch 12/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.5590 - auc: 0.7004 - loss: 0.0609\n",
      "Epoch 13/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5963 - auc: 0.7080 - loss: 0.0594\n",
      "Epoch 14/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.5870 - auc: 0.7514 - loss: 0.0572\n",
      "Epoch 15/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.6180 - auc: 0.7811 - loss: 0.0530\n",
      "Epoch 16/20\n",
      "41/41 - 1s - 33ms/step - accuracy: 0.6211 - auc: 0.7695 - loss: 0.0535\n",
      "Epoch 17/20\n",
      "41/41 - 1s - 32ms/step - accuracy: 0.6553 - auc: 0.7904 - loss: 0.0507\n",
      "Epoch 18/20\n",
      "41/41 - 1s - 20ms/step - accuracy: 0.6366 - auc: 0.8079 - loss: 0.0505\n",
      "Epoch 19/20\n",
      "41/41 - 1s - 31ms/step - accuracy: 0.6522 - auc: 0.8074 - loss: 0.0492\n",
      "Epoch 20/20\n",
      "41/41 - 1s - 19ms/step - accuracy: 0.6398 - auc: 0.8182 - loss: 0.0475\n",
      "Accuracy: 71.43%, AUC: 48.97%\n",
      "\n",
      "--- Fold 4 ---\n",
      " train balance: Counter({0.0: 157, 1.0: 38})\n",
      "  test balance: Counter({0.0: 43, 1.0: 6})\n",
      " after oversampling: Counter({0.0: 157, 1.0: 157})\n",
      "Epoch 1/20\n",
      "40/40 - 4s - 112ms/step - accuracy: 0.4777 - auc: 0.4184 - loss: 0.0832\n",
      "Epoch 2/20\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.5000 - auc: 0.4342 - loss: 0.0825\n",
      "Epoch 3/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.4809 - auc: 0.4663 - loss: 0.0805\n",
      "Epoch 4/20\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4904 - auc: 0.4699 - loss: 0.0792\n",
      "Epoch 5/20\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.5064 - auc: 0.5346 - loss: 0.0747\n",
      "Epoch 6/20\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.4841 - auc: 0.5199 - loss: 0.0756\n",
      "Epoch 7/20\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.5127 - auc: 0.5606 - loss: 0.0734\n",
      "Epoch 8/20\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.4904 - auc: 0.5263 - loss: 0.0753\n",
      "Epoch 9/20\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.5127 - auc: 0.5531 - loss: 0.0738\n",
      "Epoch 10/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.4968 - auc: 0.5467 - loss: 0.0738\n",
      "Epoch 11/20\n",
      "40/40 - 1s - 32ms/step - accuracy: 0.5064 - auc: 0.5867 - loss: 0.0713\n",
      "Epoch 12/20\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.5096 - auc: 0.5694 - loss: 0.0721\n",
      "Epoch 13/20\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.5096 - auc: 0.6414 - loss: 0.0680\n",
      "Epoch 14/20\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.5032 - auc: 0.5760 - loss: 0.0712\n",
      "Epoch 15/20\n",
      "40/40 - 1s - 32ms/step - accuracy: 0.5159 - auc: 0.6165 - loss: 0.0680\n",
      "Epoch 16/20\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.5318 - auc: 0.6562 - loss: 0.0658\n",
      "Epoch 17/20\n",
      "40/40 - 1s - 32ms/step - accuracy: 0.5223 - auc: 0.6236 - loss: 0.0675\n",
      "Epoch 18/20\n",
      "40/40 - 1s - 34ms/step - accuracy: 0.5318 - auc: 0.6760 - loss: 0.0643\n",
      "Epoch 19/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5414 - auc: 0.6526 - loss: 0.0657\n",
      "Epoch 20/20\n",
      "40/40 - 1s - 20ms/step - accuracy: 0.5382 - auc: 0.6466 - loss: 0.0655\n",
      "Accuracy: 89.80%, AUC: 57.17%\n",
      "\n",
      "--- Fold 5 ---\n",
      " train balance: Counter({0.0: 159, 1.0: 37})\n",
      "  test balance: Counter({0.0: 41, 1.0: 7})\n",
      " after oversampling: Counter({0.0: 159, 1.0: 159})\n",
      "Epoch 1/20\n",
      "40/40 - 5s - 113ms/step - accuracy: 0.4780 - auc: 0.4671 - loss: 0.0816\n",
      "Epoch 2/20\n",
      "40/40 - 1s - 19ms/step - accuracy: 0.4937 - auc: 0.4615 - loss: 0.0806\n",
      "Epoch 3/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5000 - auc: 0.4694 - loss: 0.0792\n",
      "Epoch 4/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5000 - auc: 0.4886 - loss: 0.0776\n",
      "Epoch 5/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5189 - auc: 0.5390 - loss: 0.0747\n",
      "Epoch 6/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5063 - auc: 0.5006 - loss: 0.0765\n",
      "Epoch 7/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5157 - auc: 0.4965 - loss: 0.0761\n",
      "Epoch 8/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5031 - auc: 0.5395 - loss: 0.0739\n",
      "Epoch 9/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5283 - auc: 0.5946 - loss: 0.0705\n",
      "Epoch 10/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5031 - auc: 0.6086 - loss: 0.0704\n",
      "Epoch 11/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5157 - auc: 0.5984 - loss: 0.0707\n",
      "Epoch 12/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5252 - auc: 0.5862 - loss: 0.0713\n",
      "Epoch 13/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5440 - auc: 0.6534 - loss: 0.0674\n",
      "Epoch 14/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5220 - auc: 0.6181 - loss: 0.0696\n",
      "Epoch 15/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5472 - auc: 0.6356 - loss: 0.0667\n",
      "Epoch 16/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5157 - auc: 0.6433 - loss: 0.0681\n",
      "Epoch 17/20\n",
      "40/40 - 1s - 33ms/step - accuracy: 0.5660 - auc: 0.6979 - loss: 0.0623\n",
      "Epoch 18/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5692 - auc: 0.6814 - loss: 0.0640\n",
      "Epoch 19/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5660 - auc: 0.7132 - loss: 0.0617\n",
      "Epoch 20/20\n",
      "40/40 - 1s - 18ms/step - accuracy: 0.5535 - auc: 0.6643 - loss: 0.0644\n",
      "Accuracy: 79.17%, AUC: 59.41%\n",
      "\n",
      "=== Cross‚ÄêValidation Results ===\n",
      "Mean Accuracy: 78.28% ¬± 6.39%\n",
      "Mean AUC     : 55.83% ¬± 7.90%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dropout, Dense\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "# ÂÅáËÆæ X, y, groups Â∑≤ÁªèÂáÜÂ§áÂ•Ω\n",
    "cv = GroupKFold(n_splits=5)\n",
    "cvscores, auc_scores = [], []\n",
    "\n",
    "# ÂèØÈÄâÔºöÂÆö‰πâ Focal Loss\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        return alpha_t * tf.pow(1 - p_t, gamma) * bce\n",
    "    return loss_fn\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(cv.split(X, y, groups), 1):\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "    X_tr, X_te = X[train_idx], X[test_idx]\n",
    "    y_tr, y_te = y[train_idx], y[test_idx]\n",
    "    print(\" train balance:\", Counter(y_tr))\n",
    "    print(\"  test balance:\", Counter(y_te))\n",
    "\n",
    "    # ‚Äî‚Äî 1. ËøáÈááÊ†∑Â∞ëÊï∞Á±ª ‚Äî‚Äî \n",
    "    n_s, seq_len, n_feat = X_tr.shape\n",
    "    X_flat = X_tr.reshape(n_s, -1)\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_res_flat, y_res = ros.fit_resample(X_flat, y_tr)\n",
    "    X_res = X_res_flat.reshape(-1, seq_len, n_feat)\n",
    "    print(\" after oversampling:\", Counter(y_res))\n",
    "\n",
    "    # ‚Äî‚Äî 2. ÂÆö‰πâÊ®°ÂûãÔºàÁ§∫‰æãÁî®ÂèåÂêë LSTMÔºâ ‚Äî‚Äî \n",
    "    model = Sequential([\n",
    "        Input(shape=(seq_len, n_feat)),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(12),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=focal_loss(),  # ÊàñËÄÖÁî® 'binary_crossentropy'\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4, clipnorm=1.0),\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    # ‚Äî‚Äî 3. ËÆ≠ÁªÉ ‚Äî‚Äî \n",
    "    model.fit(\n",
    "        X_res, y_res,\n",
    "        batch_size=8,\n",
    "        epochs=20,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # ‚Äî‚Äî 4. ËØÑ‰º∞ ‚Äî‚Äî \n",
    "    loss, acc, auc = model.evaluate(X_te, y_te, verbose=0)\n",
    "    print(f\"Accuracy: {acc*100:.2f}%, AUC: {auc*100:.2f}%\")\n",
    "    cvscores.append(acc*100)\n",
    "    auc_scores.append(auc*100)\n",
    "\n",
    "print(\"\\n=== Cross‚ÄêValidation Results ===\")\n",
    "print(f\"Mean Accuracy: {np.mean(cvscores):.2f}% ¬± {np.std(cvscores):.2f}%\")\n",
    "print(f\"Mean AUC     : {np.mean(auc_scores):.2f}% ¬± {np.std(auc_scores):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc374807-230d-4ed4-9048-d1e3bbf29ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8bd09c-903d-4f43-b70c-4bd8773d9c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d2167-0efd-4ae2-8605-3814be62b579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68757cd1-4a46-4023-94f6-6c70f17c9d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
